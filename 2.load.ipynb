{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing Supabase credentials. Please ensure SUPABASE_URL and SUPABASE_KEY are set in your .env.local file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUPABASE_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing Supabase credentials. Please ensure SUPABASE_URL and SUPABASE_KEY \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare set in your .env.local file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupabase credentials loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Initialize Supabase client\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Missing Supabase credentials. Please ensure SUPABASE_URL and SUPABASE_KEY are set in your .env.local file"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from supabase import create_client\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Get and verify environment variables\n",
    "url = os.environ.get(\"SUPABASE_URL\")\n",
    "key = os.environ.get(\"SUPABASE_KEY\")\n",
    "\n",
    "if not url or not key:\n",
    "    raise ValueError(\n",
    "        \"Missing Supabase credentials. Please ensure SUPABASE_URL and SUPABASE_KEY \"\n",
    "        \"are set in your .env.local file\"\n",
    "    )\n",
    "\n",
    "print(\"Supabase credentials loaded successfully\")\n",
    "\n",
    "# Initialize Supabase client\n",
    "try:\n",
    "    supabase = create_client(url, key)\n",
    "    print(\"Successfully connected to Supabase\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Supabase: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Read processed CSV files\n",
    "try:\n",
    "    tables = {\n",
    "        'census_records': pd.read_csv('data/processed/census_records.csv'),\n",
    "        'locations': pd.read_csv('data/processed/locations.csv'),\n",
    "        'persons': pd.read_csv('data/processed/persons.csv'),\n",
    "        'personal_attributes': pd.read_csv('data/processed/personal_attributes.csv'),\n",
    "        'occupations': pd.read_csv('data/processed/occupations.csv'),\n",
    "        'families': pd.read_csv('data/processed/families.csv'),\n",
    "        'relationships': pd.read_csv('data/processed/relationships.csv'),\n",
    "        'property_status': pd.read_csv('data/processed/property_status.csv'),\n",
    "        'marital_status': pd.read_csv('data/processed/marital_status.csv')\n",
    "    }\n",
    "    print(\"Successfully loaded all CSV files\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define upload function with error handling and batching\n",
    "def upload_to_supabase(table_name, df, batch_size=100):\n",
    "    \"\"\"\n",
    "    Upload dataframe to Supabase table in batches with error handling\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {table_name}...\")\n",
    "    total_rows = len(df)\n",
    "    successful_uploads = 0\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    records = df.to_dict('records')\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch = records[i:i + batch_size]\n",
    "        try:\n",
    "            # Upload batch\n",
    "            data, count = supabase.table(table_name).insert(batch).execute()\n",
    "            successful_uploads += len(batch)\n",
    "            \n",
    "            # Print progress\n",
    "            progress = (i + len(batch)) / total_rows * 100\n",
    "            print(f\"Progress: {progress:.2f}% ({successful_uploads}/{total_rows} rows)\")\n",
    "            \n",
    "            # Small delay to avoid rate limits\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch starting at row {i}: {str(e)}\")\n",
    "            # Log failed batch for retry if needed\n",
    "            with open(f'failed_{table_name}_batch_{i}.txt', 'w') as f:\n",
    "                f.write(str(batch))\n",
    "    \n",
    "    return successful_uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define upload function with error handling and batching\n",
    "def upload_to_supabase(table_name, df, batch_size=100):\n",
    "    \"\"\"\n",
    "    Upload dataframe to Supabase table in batches with error handling\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {table_name}...\")\n",
    "    total_rows = len(df)\n",
    "    successful_uploads = 0\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    records = df.to_dict('records')\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch = records[i:i + batch_size]\n",
    "        try:\n",
    "            # Upload batch\n",
    "            data, count = supabase.table(table_name).insert(batch).execute()\n",
    "            successful_uploads += len(batch)\n",
    "            \n",
    "            # Print progress\n",
    "            progress = (i + len(batch)) / total_rows * 100\n",
    "            print(f\"Progress: {progress:.2f}% ({successful_uploads}/{total_rows} rows)\")\n",
    "            \n",
    "            # Small delay to avoid rate limits\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch starting at row {i}: {str(e)}\")\n",
    "            # Log failed batch for retry if needed\n",
    "            with open(f'failed_{table_name}_batch_{i}.txt', 'w') as f:\n",
    "                f.write(str(batch))\n",
    "    \n",
    "    return successful_uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Upload order respecting foreign key constraints\n",
    "upload_order = [\n",
    "    'census_records',  # No foreign keys\n",
    "    'locations',       # Depends on census_records\n",
    "    'persons',        # No foreign keys\n",
    "    'families',       # Depends on census_records and locations\n",
    "    'personal_attributes',  # Depends on persons and census_records\n",
    "    'occupations',    # Depends on persons and census_records\n",
    "    'relationships',  # Depends on persons, families, and census_records\n",
    "    'property_status',  # Depends on persons and census_records\n",
    "    'marital_status'   # Depends on persons and census_records\n",
    "]\n",
    "\n",
    "# Track upload statistics\n",
    "upload_stats = {}\n",
    "\n",
    "# Upload tables in order\n",
    "for table_name in upload_order:\n",
    "    if table_name in tables:\n",
    "        df = tables[table_name]\n",
    "        # Remove any created_at columns as they're handled by Supabase\n",
    "        if 'created_at' in df.columns:\n",
    "            df = df.drop('created_at', axis=1)\n",
    "        \n",
    "        print(f\"\\nProcessing {table_name}...\")\n",
    "        successful_rows = upload_to_supabase(table_name, df)\n",
    "        upload_stats[table_name] = {\n",
    "            'total_rows': len(df),\n",
    "            'uploaded_rows': successful_rows\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Print upload summary\n",
    "print(\"\\nUpload Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for table_name, stats in upload_stats.items():\n",
    "    success_rate = (stats['uploaded_rows'] / stats['total_rows']) * 100\n",
    "    print(f\"{table_name}:\")\n",
    "    print(f\"  Total rows: {stats['total_rows']}\")\n",
    "    print(f\"  Uploaded rows: {stats['uploaded_rows']}\")\n",
    "    print(f\"  Success rate: {success_rate:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lakeland",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

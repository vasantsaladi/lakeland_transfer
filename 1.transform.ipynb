{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and read data\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read census files\n",
    "df_1900 = pd.read_csv('data/lakeland_1900_census.csv')\n",
    "df_1920 = pd.read_csv('data/lakeland_1920_census.csv')\n",
    "df_1930 = pd.read_csv('data/lakeland_1930_census.csv')\n",
    "df_1940 = pd.read_csv('data/lakeland_1940_census.csv')\n",
    "df_1950 = pd.read_csv('data/lakeland_1950_census.csv')\n",
    "\n",
    "census_dfs = {\n",
    "    1900: df_1900,\n",
    "    1920: df_1920,\n",
    "    1930: df_1930,\n",
    "    1940: df_1940,\n",
    "    1950: df_1950\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1900 Census Columns: ['source_pk', 'dwelling_number', 'family', 'last_name', 'first_name', 'head_last_name', 'head_first_name', 'relation_to_head', 'race', 'sex', 'age', 'marital_status', 'birth_place', 'work', 'owned_rented', 'census_year']\n",
      "\n",
      "1920 Census Columns: ['source_pk', 'dwelling_number', 'family', 'last_name', 'first_name', 'relation_to_head', 'head_last_name', 'head_first_name', 'sex', 'race', 'marital_status', 'age', 'birth_place', 'work', 'business', 'owned_rented', 'census_year']\n",
      "\n",
      "1930 Census Columns: ['source_pk', 'dwelling_number', 'family', 'street_name', 'last_name', 'first_name', 'relation_to_head', 'sex', 'race', 'marital_status', 'age', 'birth_place', 'work', 'business', 'owned_rented', 'census_year']\n",
      "\n",
      "1940 Census Columns: ['source_pk', 'ed', 'house_number', 'street_name', 'last_name', 'first_name', 'relation_to_head', 'head_last_name', 'head_first_name', 'sex', 'race', 'marital_status', 'age', 'birth_place', 'work', 'business', 'owned_rented', 'census_year']\n",
      "\n",
      "1950 Census Columns: ['source_pk', 'ed', 'house_number', 'build_num', 'street_name', 'last_name', 'first_name', 'relation_to_head', 'head_last_name', 'head_first_name', 'sex', 'race', 'marital_status', 'age', 'birth_place', 'work', 'business', 'census_year']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define column standardization function\n",
    "def standardize_columns(df, year):\n",
    "    \"\"\"Standardize column names across census years\"\"\"\n",
    "    column_mapping = {\n",
    "        'pk': 'source_pk',\n",
    "        'dwelling number': 'dwelling_number',\n",
    "        'dwelling': 'dwelling_number',\n",
    "        'house_num': 'house_number',\n",
    "        'relation_head': 'relation_to_head',\n",
    "        'head_last': 'head_last_name',\n",
    "        'head_first': 'head_first_name',\n",
    "        'marital': 'marital_status',\n",
    "        'place_birth': 'birth_place',\n",
    "        'family': 'family_number'  # Added this mapping\n",
    "    }\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    df['census_year'] = year\n",
    "    \n",
    "    # Print columns before and after standardization\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    print(\"Original columns:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "# Standardize all dataframes\n",
    "standardized_dfs = {\n",
    "    year: standardize_columns(df, year) \n",
    "    for year, df in census_dfs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'family_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year, df \u001b[38;5;129;01min\u001b[39;00m standardized_dfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_ids(df, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_ids(\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdwelling_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfamily_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mngroup(), \n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Print sample to verify\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample from 1900:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'family_number'"
     ]
    }
   ],
   "source": [
    "# Cell 3: Generate IDs for persons and families\n",
    "def generate_ids(df, prefix):\n",
    "    \"\"\"Generate string IDs with prefix\"\"\"\n",
    "    return [f\"{prefix}_{i:06d}\" for i in range(len(df))]\n",
    "\n",
    "# Add IDs to each dataframe\n",
    "for year, df in standardized_dfs.items():\n",
    "    df['person_id'] = generate_ids(df, f\"P{year}\")\n",
    "    df['family_id'] = generate_ids(\n",
    "        df.groupby(['dwelling_number', 'family_number']).ngroup(), \n",
    "        f\"F{year}\"\n",
    "    )\n",
    "\n",
    "# Print sample to verify\n",
    "print(\"Sample from 1900:\")\n",
    "print(standardized_dfs[1900][['person_id', 'family_id', 'first_name', 'last_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create census_records table\n",
    "census_records_data = []\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    census_records = pd.DataFrame({\n",
    "        'census_year': df['census_year'],\n",
    "        'source_pk': df['source_pk'],\n",
    "        'ed': df['ed'] if 'ed' in df.columns else None,\n",
    "        'page_number': None  # Add if available\n",
    "    })\n",
    "    census_records['record_id'] = range(1, len(census_records) + 1)\n",
    "    census_records_data.append(census_records)\n",
    "\n",
    "census_records_table = pd.concat(census_records_data, ignore_index=True)\n",
    "print(\"Census Records Table Sample:\")\n",
    "print(census_records_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create locations table\n",
    "locations_data = []\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    locations = pd.DataFrame({\n",
    "        'street_name': df['street_name'] if 'street_name' in df.columns else None,\n",
    "        'house_num': df['house_number'] if 'house_number' in df.columns else None,\n",
    "        'build_num': df['build_num'] if 'build_num' in df.columns else None,\n",
    "        'dwelling_number': df['dwelling_number'],\n",
    "        'family_number': df['family_number']\n",
    "    })\n",
    "    locations['location_id'] = range(1, len(locations) + 1)\n",
    "    locations_data.append(locations)\n",
    "\n",
    "locations_table = pd.concat(locations_data, ignore_index=True)\n",
    "print(\"Locations Table Sample:\")\n",
    "print(locations_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create persons table\n",
    "persons_data = []\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    persons = pd.DataFrame({\n",
    "        'person_id': df['person_id'],\n",
    "        'first_name': df['first_name'],\n",
    "        'last_name': df['last_name']\n",
    "    }).drop_duplicates()\n",
    "    persons_data.append(persons)\n",
    "\n",
    "persons_table = pd.concat(persons_data, ignore_index=True).drop_duplicates()\n",
    "print(\"Persons Table Sample:\")\n",
    "print(persons_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create personal_attributes table\n",
    "personal_attributes_data = []\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    personal_attributes = pd.DataFrame({\n",
    "        'person_id': df['person_id'],\n",
    "        'sex': df['sex'],\n",
    "        'race': df['race'],\n",
    "        'age': df['age'],\n",
    "        'place_birth': df['birth_place'] if 'birth_place' in df.columns else None\n",
    "    })\n",
    "    personal_attributes['attribute_id'] = range(1, len(personal_attributes) + 1)\n",
    "    personal_attributes_data.append(personal_attributes)\n",
    "\n",
    "personal_attributes_table = pd.concat(personal_attributes_data, ignore_index=True)\n",
    "print(\"Personal Attributes Table Sample:\")\n",
    "print(personal_attributes_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create remaining tables (occupations, families, relationships, etc.)\n",
    "# Occupations\n",
    "occupations_data = []\n",
    "for year, df in standardized_dfs.items():\n",
    "    occupations = pd.DataFrame({\n",
    "        'person_id': df['person_id'],\n",
    "        'work': df['work'],\n",
    "        'business': df['business'] if 'business' in df.columns else None\n",
    "    })\n",
    "    occupations['occupation_id'] = range(1, len(occupations) + 1)\n",
    "    occupations_data.append(occupations)\n",
    "\n",
    "occupations_table = pd.concat(occupations_data, ignore_index=True)\n",
    "\n",
    "# Families\n",
    "families_data = []\n",
    "for year, df in standardized_dfs.items():\n",
    "    families = pd.DataFrame({\n",
    "        'family_id': df['family_id'],\n",
    "        'head_first_name': df['head_first_name'],\n",
    "        'head_last_name': df['head_last_name']\n",
    "    }).drop_duplicates()\n",
    "    families_data.append(families)\n",
    "\n",
    "families_table = pd.concat(families_data, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Print samples\n",
    "print(\"Occupations Table Sample:\")\n",
    "print(occupations_table.head())\n",
    "print(\"\\nFamilies Table Sample:\")\n",
    "print(families_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Export all tables to CSV\n",
    "# Create processed directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Dictionary of all tables\n",
    "tables = {\n",
    "    'census_records': census_records_table,\n",
    "    'locations': locations_table,\n",
    "    'persons': persons_table,\n",
    "    'personal_attributes': personal_attributes_table,\n",
    "    'occupations': occupations_table,\n",
    "    'families': families_table\n",
    "}\n",
    "\n",
    "# Export each table\n",
    "for table_name, df in tables.items():\n",
    "    output_path = f'data/processed/{table_name}.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Exported {table_name} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Verify data integrity\n",
    "# Print summary statistics for each table\n",
    "for table_name, df in tables.items():\n",
    "    print(f\"\\n{table_name} Summary:\")\n",
    "    print(f\"Number of rows: {len(df)}\")\n",
    "    print(f\"Number of unique person_ids: {len(df['person_id'].unique()) if 'person_id' in df.columns else 'N/A'}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

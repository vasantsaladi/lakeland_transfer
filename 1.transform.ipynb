{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Schema Verification and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Define schema requirements\n",
    "schema = {\n",
    "    'census_records': {\n",
    "        'required_columns': ['record_id', 'census_year', 'source_pk'],\n",
    "        'integer_columns': ['record_id', 'census_year', 'source_pk'],\n",
    "        'varchar_columns': ['ed', 'page_number']\n",
    "    },\n",
    "    'locations': {\n",
    "        'required_columns': ['location_id', 'record_id'],\n",
    "        'integer_columns': ['location_id', 'record_id'],\n",
    "        'varchar_columns': ['street_name', 'house_num', 'build_num', 'dwelling_number', 'family_number']\n",
    "    },\n",
    "    'persons': {\n",
    "        'required_columns': ['person_id', 'first_name', 'last_name'],\n",
    "        'varchar_columns': ['person_id', 'first_name', 'last_name']\n",
    "    },\n",
    "    'personal_attributes': {\n",
    "        'required_columns': ['attribute_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['attribute_id', 'record_id', 'age'],\n",
    "        'varchar_columns': ['person_id', 'sex', 'race', 'place_birth']\n",
    "    },\n",
    "    'occupations': {\n",
    "        'required_columns': ['occupation_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['occupation_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'work', 'business']\n",
    "    },\n",
    "    'families': {\n",
    "        'required_columns': ['family_id', 'record_id', 'location_id'],\n",
    "        'integer_columns': ['record_id', 'location_id'],\n",
    "        'varchar_columns': ['family_id', 'head_first_name', 'head_last_name']\n",
    "    },\n",
    "    'relationships': {\n",
    "        'required_columns': ['relationship_id', 'person_id', 'family_id', 'record_id'],\n",
    "        'integer_columns': ['relationship_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'family_id', 'relation_to_head']\n",
    "    },\n",
    "    'property_status': {\n",
    "        'required_columns': ['property_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['property_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'owned_rented']\n",
    "    },\n",
    "    'marital_status': {\n",
    "        'required_columns': ['marital_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['marital_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'marital_status']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading census data...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Read Census Data\n",
    "print(\"Reading census data...\")\n",
    "# Read the extracted CSV files\n",
    "census_dfs = {\n",
    "    1900: pd.read_csv('data/extracted/lakeland_1900_census.csv'),\n",
    "    1920: pd.read_csv('data/extracted/lakeland_1920_census.csv'),\n",
    "    1930: pd.read_csv('data/extracted/lakeland_1930_census.csv'),\n",
    "    1940: pd.read_csv('data/extracted/lakeland_1940_census.csv'),\n",
    "    1950: pd.read_csv('data/extracted/lakeland_1950_census.csv')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 1900 census...\n",
      "Standardizing 1920 census...\n",
      "Standardizing 1930 census...\n",
      "Standardizing 1940 census...\n",
      "Standardizing 1950 census...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Standardize Columns\n",
    "def standardize_columns(df, year):\n",
    "    \"\"\"Standardize column names to match database schema\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert column names to lowercase and strip whitespace\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Standard column mappings\n",
    "    column_mapping = {\n",
    "        'pk': 'source_pk',\n",
    "        'dwelling number': 'dwelling_number',\n",
    "        'dwelling': 'dwelling_number',\n",
    "        'dwelling no': 'dwelling_number',\n",
    "        'dwelling_no': 'dwelling_number',\n",
    "        'house_number': 'house_num',\n",
    "        'house number': 'house_num',\n",
    "        'relation_head': 'relation_to_head',\n",
    "        'relation to head': 'relation_to_head',\n",
    "        'head_last': 'head_last_name',\n",
    "        'head last': 'head_last_name',\n",
    "        'head_first': 'head_first_name',\n",
    "        'head first': 'head_first_name',\n",
    "        'marital': 'marital_status',\n",
    "        'birth_place': 'place_birth',\n",
    "        'birth place': 'place_birth',\n",
    "        'family': 'family_number',\n",
    "        'family no': 'family_number',\n",
    "        'family_no': 'family_number',\n",
    "        'family number': 'family_number'\n",
    "    }\n",
    "    \n",
    "    # Apply mappings\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    df['census_year'] = year\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create standardized dataframes\n",
    "standardized_dfs = {}\n",
    "for year, df in census_dfs.items():\n",
    "    print(f\"Standardizing {year} census...\")\n",
    "    standardized_dfs[year] = standardize_columns(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create census_records table\n",
    "census_records_data = []\n",
    "record_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    census_records = pd.DataFrame({\n",
    "        'record_id': range(record_id_counter, record_id_counter + len(df)),\n",
    "        'census_year': df['census_year'].astype('Int64'),\n",
    "        'source_pk': df['source_pk'].astype('Int64'),\n",
    "        'ed': df['ed'] if 'ed' in df.columns else None,\n",
    "        'page_number': df['page_number'] if 'page_number' in df.columns else None\n",
    "    })\n",
    "    record_id_counter += len(df)\n",
    "    census_records_data.append(census_records)\n",
    "\n",
    "census_records_table = pd.concat(census_records_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create persons table with unique IDs\n",
    "def generate_person_id(year, index):\n",
    "    return f\"P{year}_{index:06d}\"\n",
    "\n",
    "persons_data = []\n",
    "for year, df in standardized_dfs.items():\n",
    "    persons = pd.DataFrame({\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'first_name': df['first_name'],\n",
    "        'last_name': df['last_name']\n",
    "    })\n",
    "    persons_data.append(persons)\n",
    "\n",
    "persons_table = pd.concat(persons_data, ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Created sequential dwelling_number for 1940 census\n",
      "Warning: Created sequential family_number for 1940 census\n",
      "Warning: Created sequential dwelling_number for 1950 census\n",
      "Warning: Created sequential family_number for 1950 census\n",
      "\n",
      "Locations Table Sample:\n",
      "   location_id  record_id street_name  house_num build_num  dwelling_number  \\\n",
      "0            1        612        None        NaN      None             32.0   \n",
      "1            2        613        None        NaN      None             32.0   \n",
      "2            3        614        None        NaN      None             32.0   \n",
      "3            4        615        None        NaN      None             32.0   \n",
      "4            5        616        None        NaN      None             32.0   \n",
      "\n",
      "   family_number  \n",
      "0           32.0  \n",
      "1           32.0  \n",
      "2           32.0  \n",
      "3           32.0  \n",
      "4           32.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bb/h215m9_n4s942nm7pw18_zrr0000gn/T/ipykernel_4281/1557219654.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  locations_table = pd.concat(locations_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create locations table\n",
    "locations_data = []\n",
    "location_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    # Create a base DataFrame with the required columns\n",
    "    locations = pd.DataFrame({\n",
    "        'location_id': range(location_id_counter, location_id_counter + len(df)),\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter)\n",
    "    })\n",
    "    \n",
    "    # Add optional columns if they exist, otherwise use None\n",
    "    optional_columns = {\n",
    "        'street_name': None,\n",
    "        'house_num': None,\n",
    "        'build_num': None,\n",
    "        'dwelling_number': None,\n",
    "        'family_number': None\n",
    "    }\n",
    "    \n",
    "    for col, default in optional_columns.items():\n",
    "        locations[col] = df[col] if col in df.columns else default\n",
    "        \n",
    "    # If dwelling_number is missing, create it from index\n",
    "    if locations['dwelling_number'].isna().all():\n",
    "        locations['dwelling_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential dwelling_number for {year} census\")\n",
    "    \n",
    "    # If family_number is missing, create it from index\n",
    "    if locations['family_number'].isna().all():\n",
    "        locations['family_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential family_number for {year} census\")\n",
    "    \n",
    "    location_id_counter += len(df)\n",
    "    locations_data.append(locations)\n",
    "\n",
    "locations_table = pd.concat(locations_data, ignore_index=True)\n",
    "\n",
    "# Print sample of the locations table\n",
    "print(\"\\nLocations Table Sample:\")\n",
    "print(locations_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 1900...\n",
      "Created 50 family records for year 1900\n",
      "\n",
      "Processing year 1920...\n",
      "Created 33 family records for year 1920\n",
      "\n",
      "Processing year 1930...\n",
      "Created 10 family records for year 1930\n",
      "\n",
      "Processing year 1940...\n",
      "Warning: Created sequential dwelling_number for 1940\n",
      "Warning: Created sequential family_number for 1940\n",
      "Created 61 family records for year 1940\n",
      "\n",
      "Processing year 1950...\n",
      "Warning: Created sequential dwelling_number for 1950\n",
      "Warning: Created sequential family_number for 1950\n",
      "Created 314 family records for year 1950\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0  F1900_000000        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "\n",
      "Family ID Statistics:\n",
      "Total number of families: 468\n",
      "Number of unique family IDs: 468\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create families table\n",
    "def generate_family_id(year, index):\n",
    "    return f\"F{year}_{index:06d}\"\n",
    "\n",
    "def ensure_family_columns(df, year):\n",
    "    \"\"\"Ensure required family columns exist and are properly formatted\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create dwelling_number if missing\n",
    "    if 'dwelling_number' not in df.columns:\n",
    "        df['dwelling_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential dwelling_number for {year}\")\n",
    "    \n",
    "    # Create family_number if missing\n",
    "    if 'family_number' not in df.columns:\n",
    "        df['family_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential family_number for {year}\")\n",
    "    \n",
    "    # Convert to string and handle NaN values\n",
    "    df['dwelling_number'] = df['dwelling_number'].fillna(0).astype(int).astype(str)\n",
    "    df['family_number'] = df['family_number'].fillna(0).astype(int).astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "families_data = []\n",
    "family_id_maps = {}  # Store family ID mappings for each year\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    try:\n",
    "        print(f\"\\nProcessing year {year}...\")\n",
    "        \n",
    "        # Ensure required columns exist and are properly formatted\n",
    "        df = ensure_family_columns(df, year)\n",
    "        \n",
    "        # Group by dwelling and family number\n",
    "        family_groups = df.groupby(['dwelling_number', 'family_number'])\n",
    "        \n",
    "        # Get the first record for each family group\n",
    "        first_records = family_groups.first().reset_index()\n",
    "        num_families = len(first_records)\n",
    "        \n",
    "        # Create family IDs and store mapping\n",
    "        family_ids = [generate_family_id(year, i) for i in range(num_families)]\n",
    "        family_id_maps[year] = dict(zip(\n",
    "            zip(first_records['dwelling_number'], first_records['family_number']),\n",
    "            family_ids\n",
    "        ))\n",
    "        \n",
    "        # Create the families DataFrame\n",
    "        families = pd.DataFrame({\n",
    "            'family_id': family_ids,\n",
    "            'record_id': range(record_id_counter - num_families, record_id_counter),\n",
    "            'location_id': range(location_id_counter - num_families, location_id_counter),\n",
    "            'head_first_name': first_records['head_first_name'] if 'head_first_name' in first_records.columns else None,\n",
    "            'head_last_name': first_records['head_last_name'] if 'head_last_name' in first_records.columns else None\n",
    "        })\n",
    "        \n",
    "        families_data.append(families)\n",
    "        print(f\"Created {num_families} family records for year {year}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing year {year}\")\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "families_table = pd.concat(families_data, ignore_index=True)\n",
    "\n",
    "# Print sample and statistics\n",
    "print(\"\\nFamilies Table Sample:\")\n",
    "print(families_table.head())\n",
    "print(\"\\nFamily ID Statistics:\")\n",
    "print(f\"Total number of families: {len(families_table)}\")\n",
    "print(f\"Number of unique family IDs: {len(families_table['family_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create personal_attributes table\n",
    "def clean_age(age):\n",
    "    \"\"\"Convert age to integer, handling fractions\"\"\"\n",
    "    if pd.isna(age):\n",
    "        return None\n",
    "    try:\n",
    "        return int(float(age))\n",
    "    except (ValueError, TypeError):\n",
    "        if isinstance(age, str) and '/' in age:\n",
    "            num, denom = map(int, age.split('/'))\n",
    "            return max(0, int(num / denom))\n",
    "        return None\n",
    "\n",
    "personal_attributes_data = []\n",
    "attribute_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    attributes = pd.DataFrame({\n",
    "        'attribute_id': range(attribute_id_counter, attribute_id_counter + len(df)),\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "        'sex': df['sex'],\n",
    "        'race': df['race'],\n",
    "        'age': df['age'].apply(clean_age),\n",
    "        'place_birth': df['place_birth'] if 'place_birth' in df.columns else None\n",
    "    })\n",
    "    attribute_id_counter += len(df)\n",
    "    personal_attributes_data.append(attributes)\n",
    "\n",
    "personal_attributes_table = pd.concat(personal_attributes_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create occupations table\n",
    "occupations_data = []\n",
    "occupation_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    occupations = pd.DataFrame({\n",
    "        'occupation_id': range(occupation_id_counter, occupation_id_counter + len(df)),\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "        'work': df['work'].replace({np.nan: None}),\n",
    "        'business': df['business'].replace({np.nan: None}) if 'business' in df.columns else None\n",
    "    })\n",
    "    occupation_id_counter += len(df)\n",
    "    occupations_data.append(occupations)\n",
    "\n",
    "occupations_table = pd.concat(occupations_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 186 relationship records for year 1900\n",
      "Created 186 relationship records for year 1920\n",
      "Created 50 relationship records for year 1930\n",
      "Created 61 relationship records for year 1940\n",
      "Created 314 relationship records for year 1950\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0  F1900_000000        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "\n",
      "Relationships Table Sample:\n",
      "   relationship_id     person_id     family_id  record_id relation_to_head\n",
      "0                1  P1900_000000  F1900_000000        612             Head\n",
      "1                2  P1900_000001  F1900_000000        613             Wife\n",
      "2                3  P1900_000002  F1900_000000        614              Son\n",
      "3                4  P1900_000003  F1900_000000        615              Son\n",
      "4                5  P1900_000004  F1900_000000        616              Son\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Create relationships table using the same family IDs\n",
    "relationships_data = []\n",
    "relationship_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    try:\n",
    "        # Ensure required columns exist\n",
    "        if 'dwelling_number' not in df.columns:\n",
    "            df['dwelling_number'] = range(1, len(df) + 1)\n",
    "        if 'family_number' not in df.columns:\n",
    "            df['family_number'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Get the family ID mapping for this year\n",
    "        year_family_map = family_id_maps[year]\n",
    "        \n",
    "        # Create family IDs using the same mapping as families table\n",
    "        family_ids = [year_family_map.get((d, f), generate_family_id(year, 0)) \n",
    "                     for d, f in zip(df['dwelling_number'], df['family_number'])]\n",
    "        \n",
    "        # Create relationships DataFrame\n",
    "        relationships = pd.DataFrame({\n",
    "            'relationship_id': range(relationship_id_counter, relationship_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'family_id': family_ids,\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'relation_to_head': df['relation_to_head'].fillna('Unknown')\n",
    "        })\n",
    "        \n",
    "        relationship_id_counter += len(df)\n",
    "        relationships_data.append(relationships)\n",
    "        print(f\"Created {len(relationships)} relationship records for year {year}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {str(e)}\")\n",
    "        print(\"DataFrame columns:\", df.columns.tolist())\n",
    "        raise\n",
    "\n",
    "relationships_table = pd.concat(relationships_data, ignore_index=True)\n",
    "\n",
    "# Print samples to verify\n",
    "print(\"\\nFamilies Table Sample:\")\n",
    "print(families_table.head())\n",
    "print(\"\\nRelationships Table Sample:\")\n",
    "print(relationships_table.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create property_status table\n",
    "property_status_data = []\n",
    "property_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    if 'owned_rented' in df.columns:\n",
    "        property_status = pd.DataFrame({\n",
    "            'property_id': range(property_id_counter, property_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'owned_rented': df['owned_rented'].replace({np.nan: None})\n",
    "        })\n",
    "        property_id_counter += len(df)\n",
    "        property_status_data.append(property_status)\n",
    "\n",
    "property_status_table = pd.concat(property_status_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Create marital_status table\n",
    "marital_status_data = []\n",
    "marital_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    if 'marital_status' in df.columns:\n",
    "        marital = pd.DataFrame({\n",
    "            'marital_id': range(marital_id_counter, marital_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'marital_status': df['marital_status'].replace({np.nan: None})\n",
    "        })\n",
    "        marital_id_counter += len(df)\n",
    "        marital_status_data.append(marital)\n",
    "\n",
    "marital_status_table = pd.concat(marital_status_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debugging family IDs:\n",
      "\n",
      "Families table sample:\n",
      "      family_id\n",
      "0  F1900_000000\n",
      "1  F1900_000001\n",
      "2  F1900_000002\n",
      "3  F1900_000003\n",
      "4  F1900_000004\n",
      "\n",
      "Relationships table sample:\n",
      "      family_id\n",
      "0  F1900_000000\n",
      "1  F1900_000000\n",
      "2  F1900_000000\n",
      "3  F1900_000000\n",
      "4  F1900_000000\n",
      "\n",
      "Family ID counts:\n",
      "Number of unique family IDs in families table: 468\n",
      "Number of unique family IDs in relationships table: 5\n",
      "\n",
      "Debugging family IDs:\n",
      "Number of unique family IDs in families table: 468\n",
      "Number of unique family IDs in relationships table: 5\n",
      "All foreign key relationships verified!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Verify foreign key relationships\n",
    "def verify_foreign_keys():\n",
    "    \"\"\"Verify all foreign key relationships match the database schema\"\"\"\n",
    "    # Get all unique IDs from primary tables\n",
    "    record_ids = set(census_records_table['record_id'])\n",
    "    person_ids = set(persons_table['person_id'])\n",
    "    location_ids = set(locations_table['location_id'])\n",
    "    family_ids = set(families_table['family_id'])\n",
    "    \n",
    "    # Debug family IDs\n",
    "    print(\"\\nDebugging family IDs:\")\n",
    "    print(f\"Number of unique family IDs in families table: {len(family_ids)}\")\n",
    "    print(f\"Number of unique family IDs in relationships table: {len(set(relationships_table['family_id']))}\")\n",
    "    \n",
    "    # Find mismatched family IDs\n",
    "    relationship_family_ids = set(relationships_table['family_id'])\n",
    "    mismatched_ids = relationship_family_ids - family_ids\n",
    "    if mismatched_ids:\n",
    "        print(\"\\nExample of mismatched family IDs:\")\n",
    "        print(\"First 5 mismatched IDs:\", list(mismatched_ids)[:5])\n",
    "        print(\"\\nExample records from families table:\")\n",
    "        print(families_table[['family_id']].head())\n",
    "        print(\"\\nExample records from relationships table:\")\n",
    "        print(relationships_table[['family_id']].head())\n",
    "        raise AssertionError(f\"Found {len(mismatched_ids)} family IDs in relationships table that don't exist in families table\")\n",
    "\n",
    "    # Verify locations foreign keys\n",
    "    assert all(rid in record_ids for rid in locations_table['record_id']), \\\n",
    "        \"Invalid record_id in locations table\"\n",
    "\n",
    "    # Verify families foreign keys\n",
    "    assert all(rid in record_ids for rid in families_table['record_id']), \\\n",
    "        \"Invalid record_id in families table\"\n",
    "    assert all(lid in location_ids for lid in families_table['location_id']), \\\n",
    "        \"Invalid location_id in families table\"\n",
    "\n",
    "    # Verify personal_attributes foreign keys\n",
    "    assert all(pid in person_ids for pid in personal_attributes_table['person_id']), \\\n",
    "        \"Invalid person_id in personal_attributes table\"\n",
    "    assert all(rid in record_ids for rid in personal_attributes_table['record_id']), \\\n",
    "        \"Invalid record_id in personal_attributes table\"\n",
    "\n",
    "    # Verify occupations foreign keys\n",
    "    assert all(pid in person_ids for pid in occupations_table['person_id']), \\\n",
    "        \"Invalid person_id in occupations table\"\n",
    "    assert all(rid in record_ids for rid in occupations_table['record_id']), \\\n",
    "        \"Invalid record_id in occupations table\"\n",
    "\n",
    "    # Verify relationships foreign keys\n",
    "    assert all(pid in person_ids for pid in relationships_table['person_id']), \\\n",
    "        \"Invalid person_id in relationships table\"\n",
    "    assert all(fid in family_ids for fid in relationships_table['family_id']), \\\n",
    "        \"Invalid family_id in relationships table\"\n",
    "    assert all(rid in record_ids for rid in relationships_table['record_id']), \\\n",
    "        \"Invalid record_id in relationships table\"\n",
    "\n",
    "    print(\"All foreign key relationships verified!\")\n",
    "\n",
    "# Debug family IDs\n",
    "print(\"\\nDebugging family IDs:\")\n",
    "print(\"\\nFamilies table sample:\")\n",
    "print(families_table[['family_id']].head())\n",
    "print(\"\\nRelationships table sample:\")\n",
    "print(relationships_table[['family_id']].head())\n",
    "\n",
    "print(\"\\nFamily ID counts:\")\n",
    "print(f\"Number of unique family IDs in families table: {len(set(families_table['family_id']))}\")\n",
    "print(f\"Number of unique family IDs in relationships table: {len(set(relationships_table['family_id']))}\")\n",
    "\n",
    "# Find some mismatched IDs\n",
    "family_ids = set(families_table['family_id'])\n",
    "relationship_family_ids = set(relationships_table['family_id'])\n",
    "mismatched_ids = relationship_family_ids - family_ids\n",
    "if mismatched_ids:\n",
    "    print(\"\\nFirst 5 family IDs that exist in relationships but not in families:\")\n",
    "    print(list(mismatched_ids)[:5])\n",
    "    \n",
    "# Verify foreign keys\n",
    "verify_foreign_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data types to match PostgreSQL schema...\n",
      "\n",
      "Verifying data types after conversion:\n",
      "\n",
      "Locations table string columns:\n",
      "\n",
      "house_num:\n",
      "Sample values: [None, None, None, None, None]\n",
      "Data type: object\n",
      "\n",
      "dwelling_number:\n",
      "Sample values: ['32', '32', '32', '32', '32']\n",
      "Data type: object\n",
      "\n",
      "family_number:\n",
      "Sample values: ['32', '32', '32', '32', '32']\n",
      "Data type: object\n",
      "\n",
      "Personal attributes age column:\n",
      "Sample values: [58.0, 56.0, 22.0, 20.0, 15.0]\n",
      "Data type: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Data Type Conversion\n",
    "def convert_to_string(value):\n",
    "    \"\"\"Convert value to string, handling NaN and None\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Remove .0 from float strings\n",
    "    str_val = str(value).rstrip('.0')\n",
    "    return str_val if str_val != 'nan' else None\n",
    "\n",
    "def convert_to_integer(value):\n",
    "    \"\"\"Convert value to integer, handling NaN and None\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # First convert to float to handle any decimal values\n",
    "        float_val = float(value)\n",
    "        # Then convert to int, rounding down\n",
    "        return int(float_val)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def convert_to_postgres_types():\n",
    "    \"\"\"Convert DataFrame columns to match PostgreSQL schema types\"\"\"\n",
    "    global locations_table, census_records_table, personal_attributes_table\n",
    "    global persons_table, occupations_table, families_table\n",
    "    global relationships_table, property_status_table, marital_status_table\n",
    "    \n",
    "    # Convert locations table string columns\n",
    "    string_cols = ['street_name', 'house_num', 'build_num', 'dwelling_number', 'family_number']\n",
    "    for col in string_cols:\n",
    "        if col in locations_table.columns:\n",
    "            locations_table[col] = locations_table[col].apply(convert_to_string)\n",
    "    \n",
    "    # Convert census_records integer columns\n",
    "    census_records_table['census_year'] = census_records_table['census_year'].apply(convert_to_integer)\n",
    "    census_records_table['source_pk'] = census_records_table['source_pk'].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert census_records string columns\n",
    "    for col in ['ed', 'page_number']:\n",
    "        if col in census_records_table.columns:\n",
    "            census_records_table[col] = census_records_table[col].apply(convert_to_string)\n",
    "    \n",
    "    # Convert personal_attributes age to integer\n",
    "    if 'age' in personal_attributes_table.columns:\n",
    "        personal_attributes_table['age'] = personal_attributes_table['age'].apply(convert_to_integer)\n",
    "    \n",
    "    # Ensure all record_id fields are integers\n",
    "    for table in [locations_table, personal_attributes_table, occupations_table, \n",
    "                 families_table, relationships_table, property_status_table, \n",
    "                 marital_status_table]:\n",
    "        if 'record_id' in table.columns:\n",
    "            table['record_id'] = table['record_id'].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert IDENTITY columns to integers\n",
    "    id_columns = {\n",
    "        'locations_table': ['location_id'],\n",
    "        'personal_attributes_table': ['attribute_id'],\n",
    "        'occupations_table': ['occupation_id'],\n",
    "        'relationships_table': ['relationship_id'],\n",
    "        'property_status_table': ['property_id'],\n",
    "        'marital_status_table': ['marital_id']\n",
    "    }\n",
    "    \n",
    "    for table_name, columns in id_columns.items():\n",
    "        df = eval(table_name)\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert all varchar columns\n",
    "    varchar_columns = {\n",
    "        'persons_table': ['person_id', 'first_name', 'last_name'],\n",
    "        'personal_attributes_table': ['person_id', 'sex', 'race', 'place_birth'],\n",
    "        'occupations_table': ['person_id', 'work', 'business'],\n",
    "        'families_table': ['family_id', 'head_first_name', 'head_last_name'],\n",
    "        'relationships_table': ['person_id', 'family_id', 'relation_to_head'],\n",
    "        'property_status_table': ['person_id', 'owned_rented'],\n",
    "        'marital_status_table': ['person_id', 'marital_status']\n",
    "    }\n",
    "    \n",
    "    for table_name, columns in varchar_columns.items():\n",
    "        df = eval(table_name)\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(convert_to_string)\n",
    "\n",
    "# Run conversion\n",
    "print(\"Converting data types to match PostgreSQL schema...\")\n",
    "convert_to_postgres_types()\n",
    "\n",
    "# Verify conversions\n",
    "print(\"\\nVerifying data types after conversion:\")\n",
    "\n",
    "# Check locations table string columns\n",
    "print(\"\\nLocations table string columns:\")\n",
    "for col in ['house_num', 'dwelling_number', 'family_number']:\n",
    "    if col in locations_table.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"Sample values:\", locations_table[col].head().tolist())\n",
    "        print(\"Data type:\", locations_table[col].dtype)\n",
    "\n",
    "# Check personal_attributes age column\n",
    "print(\"\\nPersonal attributes age column:\")\n",
    "if 'age' in personal_attributes_table.columns:\n",
    "    print(\"Sample values:\", personal_attributes_table['age'].head().tolist())\n",
    "    print(\"Data type:\", personal_attributes_table['age'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting tables to CSV...\n",
      "Exported census_records to data/processed/census_records.csv\n",
      "\n",
      "Census_Records Table Sample:\n",
      "   record_id  census_year  source_pk    ed page_number\n",
      "0          1         1900          1  None        None\n",
      "1          2         1900          2  None        None\n",
      "2          3         1900          3  None        None\n",
      "3          4         1900          4  None        None\n",
      "4          5         1900          5  None        None\n",
      "Exported locations to data/processed/locations.csv\n",
      "\n",
      "Locations Table Sample:\n",
      "   location_id  record_id street_name house_num build_num dwelling_number  \\\n",
      "0            1        612        None      None      None              32   \n",
      "1            2        613        None      None      None              32   \n",
      "2            3        614        None      None      None              32   \n",
      "3            4        615        None      None      None              32   \n",
      "4            5        616        None      None      None              32   \n",
      "\n",
      "  family_number  \n",
      "0            32  \n",
      "1            32  \n",
      "2            32  \n",
      "3            32  \n",
      "4            32  \n",
      "Exported persons to data/processed/persons.csv\n",
      "\n",
      "Persons Table Sample:\n",
      "      person_id first_name      last_name\n",
      "0        P1900_       Ezra  Vanvalkenburg\n",
      "1  P1900_000001     Hattie  Vanvalkenburg\n",
      "2  P1900_000002    William  Vanvalkenburg\n",
      "3  P1900_000003        Jay  Vanvalkenburg\n",
      "4  P1900_000004     Jessie  Vanvalkenburg\n",
      "Exported personal_attributes to data/processed/personal_attributes.csv\n",
      "\n",
      "Personal_Attributes Table Sample:\n",
      "   attribute_id     person_id  record_id sex race   age place_birth\n",
      "0             1        P1900_        612   M    W  58.0    New York\n",
      "1             2  P1900_000001        613   F    W  56.0    New York\n",
      "2             3  P1900_000002        614   M    W  22.0    New York\n",
      "3             4  P1900_000003        615   M    W  20.0    New York\n",
      "4             5  P1900_000004        616   F    W  15.0    New York\n",
      "Exported occupations to data/processed/occupations.csv\n",
      "\n",
      "Occupations Table Sample:\n",
      "   occupation_id     person_id  record_id         work business\n",
      "0              1        P1900_        612     Merchant     None\n",
      "1              2  P1900_000001        613         None     None\n",
      "2              3  P1900_000002        614  Bakes Bread     None\n",
      "3              4  P1900_000003        615        Baker     None\n",
      "4              5  P1900_000004        616    At School     None\n",
      "Exported families to data/processed/families.csv\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0        F1900_        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "Exported relationships to data/processed/relationships.csv\n",
      "\n",
      "Relationships Table Sample:\n",
      "   relationship_id     person_id family_id  record_id relation_to_head\n",
      "0                1        P1900_    F1900_        612             Head\n",
      "1                2  P1900_000001    F1900_        613             Wife\n",
      "2                3  P1900_000002    F1900_        614              Son\n",
      "3                4  P1900_000003    F1900_        615              Son\n",
      "4                5  P1900_000004    F1900_        616              Son\n",
      "Exported property_status to data/processed/property_status.csv\n",
      "\n",
      "Property_Status Table Sample:\n",
      "   property_id     person_id  record_id owned_rented\n",
      "0            1        P1900_        612            O\n",
      "1            2  P1900_000001        613         None\n",
      "2            3  P1900_000002        614         None\n",
      "3            4  P1900_000003        615         None\n",
      "4            5  P1900_000004        616         None\n",
      "Exported marital_status to data/processed/marital_status.csv\n",
      "\n",
      "Marital_Status Table Sample:\n",
      "   marital_id     person_id  record_id marital_status\n",
      "0           1        P1900_        612              M\n",
      "1           2  P1900_000001        613              M\n",
      "2           3  P1900_000002        614              S\n",
      "3           4  P1900_000003        615              S\n",
      "4           5  P1900_000004        616              S\n",
      "\n",
      "All tables exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Export Tables\n",
    "# Export tables to CSV\n",
    "print(\"Exporting tables to CSV...\")\n",
    "tables_to_export = {\n",
    "    'census_records': census_records_table,\n",
    "    'locations': locations_table,\n",
    "    'persons': persons_table,\n",
    "    'personal_attributes': personal_attributes_table,\n",
    "    'occupations': occupations_table,\n",
    "    'families': families_table,\n",
    "    'relationships': relationships_table,\n",
    "    'property_status': property_status_table,\n",
    "    'marital_status': marital_status_table\n",
    "}\n",
    "\n",
    "for table_name, df in tables_to_export.items():\n",
    "    output_path = f'data/processed/{table_name}.csv'\n",
    "    df.to_csv(output_path, index=False, na_rep='NULL')\n",
    "    print(f\"Exported {table_name} to {output_path}\")\n",
    "    print(f\"\\n{table_name.title()} Table Sample:\")\n",
    "    print(df.head())\n",
    "\n",
    "print(\"\\nAll tables exported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading tables...\n",
      "Fixing locations table string columns...\n",
      "Fixing personal_attributes age column...\n",
      "Saving updated tables...\n",
      "Data type conversion complete. Showing samples:\n",
      "\n",
      "Locations table sample:\n",
      "  house_num dwelling_number family_number\n",
      "0      None            32.0          32.0\n",
      "1      None            32.0          32.0\n",
      "2      None            32.0          32.0\n",
      "3      None            32.0          32.0\n",
      "4      None            32.0          32.0\n",
      "\n",
      "Personal attributes age column sample:\n",
      "    age\n",
      "0  58.0\n",
      "1  56.0\n",
      "2  22.0\n",
      "3  20.0\n",
      "4  15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Reading tables...\")\n",
    "# Read the tables\n",
    "locations_df = pd.read_csv('data/processed/locations.csv')\n",
    "personal_attributes_df = pd.read_csv('data/processed/personal_attributes.csv')\n",
    "\n",
    "print(\"Fixing locations table string columns...\")\n",
    "# Convert numeric columns to strings in locations table\n",
    "locations_df['house_num'] = locations_df['house_num'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "locations_df['dwelling_number'] = locations_df['dwelling_number'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "locations_df['family_number'] = locations_df['family_number'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "\n",
    "print(\"Fixing personal_attributes age column...\")\n",
    "# Fix age values in personal_attributes table\n",
    "def clean_age(age):\n",
    "    if pd.isna(age):\n",
    "        return None\n",
    "    try:\n",
    "        # Handle float values\n",
    "        if isinstance(age, (int, float)):\n",
    "            return int(age)\n",
    "        # Handle string values\n",
    "        age_str = str(age).strip()\n",
    "        if age_str.replace('.', '').isdigit():\n",
    "            return int(float(age_str))\n",
    "        return None\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "personal_attributes_df['age'] = personal_attributes_df['age'].apply(clean_age)\n",
    "\n",
    "print(\"Saving updated tables...\")\n",
    "# Save the updated tables\n",
    "locations_df.to_csv('data/processed/locations.csv', index=False)\n",
    "personal_attributes_df.to_csv('data/processed/personal_attributes.csv', index=False)\n",
    "\n",
    "print(\"Data type conversion complete. Showing samples:\")\n",
    "print(\"\\nLocations table sample:\")\n",
    "print(locations_df[['house_num', 'dwelling_number', 'family_number']].head())\n",
    "print(\"\\nPersonal attributes age column sample:\")\n",
    "print(personal_attributes_df[['age']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning locations data...\n",
      "Fixed locations string columns\n",
      "\n",
      "Cleaning personal attributes data...\n",
      "Fixed age column in personal attributes\n",
      "\n",
      "Cleaning persons data...\n",
      "Found 16 records with null last names\n",
      "Fixed null last names in persons table\n",
      "\n",
      "Fixing family IDs...\n",
      "Fixed family IDs in relationships table\n",
      "\n",
      "Cleaning families data...\n",
      "Cleaned families data and fixed location IDs\n",
      "\n",
      "Final data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "def final_data_cleaning():\n",
    "    \"\"\"Perform final data cleaning before export\"\"\"\n",
    "    \n",
    "    # Fix locations data\n",
    "    print(\"Cleaning locations data...\")\n",
    "    locations_df = pd.read_csv('data/processed/locations.csv')\n",
    "    string_columns = ['house_num', 'dwelling_number', 'family_number']\n",
    "    for col in string_columns:\n",
    "        # Convert to string but keep NaN as NaN\n",
    "        locations_df[col] = locations_df[col].astype(str).replace('nan', np.nan)\n",
    "        # Remove .0 from the end of numbers\n",
    "        locations_df[col] = locations_df[col].apply(lambda x: x.replace('.0', '') if pd.notnull(x) else x)\n",
    "    locations_df.to_csv('data/processed/locations.csv', index=False)\n",
    "    print(\"Fixed locations string columns\")\n",
    "    \n",
    "    # Fix personal attributes data\n",
    "    print(\"\\nCleaning personal attributes data...\")\n",
    "    attributes_df = pd.read_csv('data/processed/personal_attributes.csv')\n",
    "    attributes_df['age'] = pd.to_numeric(attributes_df['age'], errors='coerce').astype('Int64')\n",
    "    attributes_df.to_csv('data/processed/personal_attributes.csv', index=False)\n",
    "    print(\"Fixed age column in personal attributes\")\n",
    "    \n",
    "    # Fix null last names in persons table\n",
    "    print(\"\\nCleaning persons data...\")\n",
    "    persons_df = pd.read_csv('data/processed/persons.csv')\n",
    "    null_last_names = persons_df[persons_df['last_name'].isna()]\n",
    "    if len(null_last_names) > 0:\n",
    "        print(f\"Found {len(null_last_names)} records with null last names\")\n",
    "        persons_df['last_name'] = persons_df['last_name'].fillna('Unknown')\n",
    "        persons_df.to_csv('data/processed/persons.csv', index=False)\n",
    "        print(\"Fixed null last names in persons table\")\n",
    "    \n",
    "    # Fix family IDs in relationships and families tables\n",
    "    print(\"\\nFixing family IDs...\")\n",
    "    relationships_df = pd.read_csv('data/processed/relationships.csv')\n",
    "    families_df = pd.read_csv('data/processed/families.csv')\n",
    "    \n",
    "    # Create a mapping from record_id to family_id using families table\n",
    "    family_id_map = dict(zip(families_df['record_id'], families_df['family_id']))\n",
    "    \n",
    "    # Update family IDs in relationships table based on record_id\n",
    "    relationships_df['family_id'] = relationships_df['record_id'].map(family_id_map)\n",
    "    \n",
    "    # Save updated relationships data\n",
    "    relationships_df.to_csv('data/processed/relationships.csv', index=False)\n",
    "    print(\"Fixed family IDs in relationships table\")\n",
    "    \n",
    "    # Clean families data and fix location IDs\n",
    "    print(\"\\nCleaning families data...\")\n",
    "    \n",
    "    # Create mapping from record_id to location_id using locations table\n",
    "    location_map = dict(zip(locations_df['record_id'], locations_df['location_id']))\n",
    "    \n",
    "    # Update location_ids in families table\n",
    "    families_df['location_id'] = families_df['record_id'].map(location_map)\n",
    "    \n",
    "    # Ensure correct data types for families\n",
    "    families_df['record_id'] = families_df['record_id'].astype(int)\n",
    "    families_df['location_id'] = families_df['location_id'].astype(int)\n",
    "    families_df['family_id'] = families_df['family_id'].astype(str)\n",
    "    \n",
    "    # Fill any null values in head names\n",
    "    families_df['head_first_name'] = families_df['head_first_name'].fillna('Unknown')\n",
    "    families_df['head_last_name'] = families_df['head_last_name'].fillna('Unknown')\n",
    "    \n",
    "    families_df.to_csv('data/processed/families.csv', index=False)\n",
    "    print(\"Cleaned families data and fixed location IDs\")\n",
    "    \n",
    "    print(\"\\nFinal data cleaning complete!\")\n",
    "\n",
    "# Run final cleaning\n",
    "final_data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformation Validation Report\n",
      "================================================================================\n",
      "\n",
      "1. File Existence Check:\n",
      "--------------------------------------------------\n",
      "✓ census_records.csv found with 797 rows\n",
      "✓ persons.csv found with 797 rows\n",
      "✓ locations.csv found with 797 rows\n",
      "✓ families.csv found with 468 rows\n",
      "✓ personal_attributes.csv found with 797 rows\n",
      "✓ occupations.csv found with 797 rows\n",
      "✓ property_status.csv found with 483 rows\n",
      "✓ marital_status.csv found with 797 rows\n",
      "✓ relationships.csv found with 797 rows\n",
      "\n",
      "2. Schema Validation:\n",
      "--------------------------------------------------\n",
      "\n",
      "census_records:\n",
      "✓ All required columns present\n",
      "  Total columns: 5\n",
      "  Columns: record_id, census_year, source_pk, ed, page_number\n",
      "\n",
      "persons:\n",
      "✓ All required columns present\n",
      "  Total columns: 3\n",
      "  Columns: person_id, first_name, last_name\n",
      "\n",
      "locations:\n",
      "✓ All required columns present\n",
      "  Total columns: 7\n",
      "  Columns: location_id, record_id, street_name, house_num, build_num, dwelling_number, family_number\n",
      "\n",
      "families:\n",
      "✓ All required columns present\n",
      "  Total columns: 5\n",
      "  Columns: family_id, record_id, location_id, head_first_name, head_last_name\n",
      "\n",
      "personal_attributes:\n",
      "✓ All required columns present\n",
      "  Total columns: 7\n",
      "  Columns: attribute_id, person_id, record_id, sex, race, age, place_birth\n",
      "\n",
      "occupations:\n",
      "✓ All required columns present\n",
      "  Total columns: 5\n",
      "  Columns: occupation_id, person_id, record_id, work, business\n",
      "\n",
      "property_status:\n",
      "✓ All required columns present\n",
      "  Total columns: 4\n",
      "  Columns: property_id, person_id, record_id, owned_rented\n",
      "\n",
      "marital_status:\n",
      "✓ All required columns present\n",
      "  Total columns: 4\n",
      "  Columns: marital_id, person_id, record_id, marital_status\n",
      "\n",
      "relationships:\n",
      "✓ All required columns present\n",
      "  Total columns: 5\n",
      "  Columns: relationship_id, person_id, family_id, record_id, relation_to_head\n",
      "\n",
      "3. Data Quality Check:\n",
      "--------------------------------------------------\n",
      "\n",
      "census_records:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate record_id values\n",
      "\n",
      "persons:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate person_id values\n",
      "\n",
      "locations:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate location_id values\n",
      "\n",
      "families:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate family_id values\n",
      "\n",
      "personal_attributes:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate attribute_id values\n",
      "\n",
      "occupations:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate occupation_id values\n",
      "\n",
      "property_status:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate property_id values\n",
      "\n",
      "marital_status:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate marital_id values\n",
      "\n",
      "relationships:\n",
      "✓ No nulls in required columns\n",
      "✓ No duplicate relationship_id values\n",
      "\n",
      "4. Foreign Key Validation:\n",
      "--------------------------------------------------\n",
      "✓ locations: All record_id references valid\n",
      "✓ families: All record_id references valid\n",
      "✓ personal_attributes: All record_id references valid\n",
      "✓ occupations: All record_id references valid\n",
      "✓ property_status: All record_id references valid\n",
      "✓ marital_status: All record_id references valid\n",
      "✓ relationships: All record_id references valid\n",
      "✓ personal_attributes: All person_id references valid\n",
      "✓ occupations: All person_id references valid\n",
      "✓ property_status: All person_id references valid\n",
      "✓ marital_status: All person_id references valid\n",
      "✓ relationships: All person_id references valid\n",
      "\n",
      "5. Census Year Distribution:\n",
      "--------------------------------------------------\n",
      "\n",
      "Records by census year:\n",
      "  1900: 186 records\n",
      "  1920: 186 records\n",
      "  1930: 50 records\n",
      "  1940: 61 records\n",
      "  1950: 314 records\n",
      "\n",
      "6. Sample Data:\n",
      "--------------------------------------------------\n",
      "\n",
      "census_records (first 2 rows):\n",
      "   record_id  census_year  source_pk   ed  page_number\n",
      "0          1         1900          1  NaN          NaN\n",
      "1          2         1900          2  NaN          NaN\n",
      "--------------------------------------------------\n",
      "\n",
      "persons (first 2 rows):\n",
      "      person_id first_name      last_name\n",
      "0        P1900_       Ezra  Vanvalkenburg\n",
      "1  P1900_000001     Hattie  Vanvalkenburg\n",
      "--------------------------------------------------\n",
      "\n",
      "locations (first 2 rows):\n",
      "   location_id  record_id street_name  house_num build_num  dwelling_number  \\\n",
      "0            1        612         NaN        NaN       NaN             32.0   \n",
      "1            2        613         NaN        NaN       NaN             32.0   \n",
      "\n",
      "   family_number  \n",
      "0           32.0  \n",
      "1           32.0  \n",
      "--------------------------------------------------\n",
      "\n",
      "families (first 2 rows):\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0        F1900_        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "--------------------------------------------------\n",
      "\n",
      "personal_attributes (first 2 rows):\n",
      "   attribute_id     person_id  record_id sex race   age place_birth\n",
      "0             1        P1900_        612   M    W  58.0    New York\n",
      "1             2  P1900_000001        613   F    W  56.0    New York\n",
      "--------------------------------------------------\n",
      "\n",
      "occupations (first 2 rows):\n",
      "   occupation_id     person_id  record_id      work business\n",
      "0              1        P1900_        612  Merchant      NaN\n",
      "1              2  P1900_000001        613       NaN      NaN\n",
      "--------------------------------------------------\n",
      "\n",
      "property_status (first 2 rows):\n",
      "   property_id     person_id  record_id owned_rented\n",
      "0            1        P1900_        612            O\n",
      "1            2  P1900_000001        613          NaN\n",
      "--------------------------------------------------\n",
      "\n",
      "marital_status (first 2 rows):\n",
      "   marital_id     person_id  record_id marital_status\n",
      "0           1        P1900_        612              M\n",
      "1           2  P1900_000001        613              M\n",
      "--------------------------------------------------\n",
      "\n",
      "relationships (first 2 rows):\n",
      "   relationship_id     person_id     family_id  record_id relation_to_head\n",
      "0                1        P1900_  F1950_000128        612             Head\n",
      "1                2  P1900_000001  F1950_000129        613             Wife\n",
      "--------------------------------------------------\n",
      "\n",
      "Validation Summary:\n",
      "================================================================================\n",
      "✓ All tables present and readable\n",
      "✓ Total records processed: 797\n",
      "✓ Total families: 468\n",
      "✓ Total persons: 797\n",
      "\n",
      "Data is ready for loading if all checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Final Data Validation Summary\n",
    "def validate_transformed_data():\n",
    "    \"\"\"Comprehensive validation of transformed data before loading\"\"\"\n",
    "    \n",
    "    # Load all tables\n",
    "    tables = {}\n",
    "    expected_tables = [\n",
    "        'census_records',\n",
    "        'persons',\n",
    "        'locations',\n",
    "        'families',\n",
    "        'personal_attributes',\n",
    "        'occupations',\n",
    "        'property_status',\n",
    "        'marital_status',\n",
    "        'relationships'\n",
    "    ]\n",
    "    \n",
    "    print(\"Data Transformation Validation Report\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. File Existence Check\n",
    "    print(\"\\n1. File Existence Check:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for table in expected_tables:\n",
    "        file_path = f'data/processed/{table}.csv'\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            tables[table] = df\n",
    "            print(f\"✓ {table}.csv found with {len(df):,} rows\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"✗ {table}.csv not found!\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error reading {table}.csv: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 2. Schema Validation\n",
    "    print(\"\\n2. Schema Validation:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    required_columns = {\n",
    "        'census_records': ['record_id', 'census_year', 'source_pk'],\n",
    "        'persons': ['person_id', 'first_name', 'last_name'],\n",
    "        'locations': ['location_id', 'record_id'],\n",
    "        'families': ['family_id', 'record_id', 'location_id'],\n",
    "        'personal_attributes': ['attribute_id', 'person_id', 'record_id'],\n",
    "        'occupations': ['occupation_id', 'person_id', 'record_id'],\n",
    "        'property_status': ['property_id', 'person_id', 'record_id'],\n",
    "        'marital_status': ['marital_id', 'person_id', 'record_id'],\n",
    "        'relationships': ['relationship_id', 'person_id', 'family_id', 'record_id']\n",
    "    }\n",
    "    \n",
    "    for table, df in tables.items():\n",
    "        print(f\"\\n{table}:\")\n",
    "        missing_cols = set(required_columns[table]) - set(df.columns)\n",
    "        if missing_cols:\n",
    "            print(f\"✗ Missing required columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"✓ All required columns present\")\n",
    "        print(f\"  Total columns: {len(df.columns)}\")\n",
    "        print(f\"  Columns: {', '.join(df.columns)}\")\n",
    "    \n",
    "    # 3. Data Quality Check\n",
    "    print(\"\\n3. Data Quality Check:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for table, df in tables.items():\n",
    "        print(f\"\\n{table}:\")\n",
    "        # Check for nulls\n",
    "        null_counts = df[required_columns[table]].isnull().sum()\n",
    "        if null_counts.any():\n",
    "            print(\"✗ Null values found in required columns:\")\n",
    "            for col, count in null_counts[null_counts > 0].items():\n",
    "                print(f\"  - {col}: {count:,} nulls\")\n",
    "        else:\n",
    "            print(\"✓ No nulls in required columns\")\n",
    "        \n",
    "        # Check for duplicates in ID columns\n",
    "        id_col = [col for col in df.columns if col.endswith('_id')][0]\n",
    "        duplicates = df[id_col].duplicated().sum()\n",
    "        if duplicates:\n",
    "            print(f\"✗ Found {duplicates:,} duplicate {id_col} values\")\n",
    "        else:\n",
    "            print(f\"✓ No duplicate {id_col} values\")\n",
    "    \n",
    "    # 4. Foreign Key Validation\n",
    "    print(\"\\n4. Foreign Key Validation:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Validate record_id references\n",
    "    record_ids = set(tables['census_records']['record_id'])\n",
    "    for table, df in tables.items():\n",
    "        if table != 'census_records' and 'record_id' in df.columns:\n",
    "            invalid_refs = set(df['record_id']) - record_ids\n",
    "            if invalid_refs:\n",
    "                print(f\"✗ {table}: Found {len(invalid_refs)} invalid record_id references\")\n",
    "            else:\n",
    "                print(f\"✓ {table}: All record_id references valid\")\n",
    "    \n",
    "    # Validate person_id references\n",
    "    person_ids = set(tables['persons']['person_id'])\n",
    "    for table, df in tables.items():\n",
    "        if table != 'persons' and 'person_id' in df.columns:\n",
    "            invalid_refs = set(df['person_id']) - person_ids\n",
    "            if invalid_refs:\n",
    "                print(f\"✗ {table}: Found {len(invalid_refs)} invalid person_id references\")\n",
    "            else:\n",
    "                print(f\"✓ {table}: All person_id references valid\")\n",
    "    \n",
    "    # 5. Census Year Distribution\n",
    "    print(\"\\n5. Census Year Distribution:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    year_counts = tables['census_records']['census_year'].value_counts().sort_index()\n",
    "    print(\"\\nRecords by census year:\")\n",
    "    for year, count in year_counts.items():\n",
    "        print(f\"  {year}: {count:,} records\")\n",
    "    \n",
    "    # 6. Sample Data\n",
    "    print(\"\\n6. Sample Data:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for table, df in tables.items():\n",
    "        print(f\"\\n{table} (first 2 rows):\")\n",
    "        print(df.head(2))\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\nValidation Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"✓ All tables present and readable\")\n",
    "    print(f\"✓ Total records processed: {len(tables['census_records']):,}\")\n",
    "    print(f\"✓ Total families: {len(tables['families']):,}\")\n",
    "    print(f\"✓ Total persons: {len(tables['persons']):,}\")\n",
    "    print(\"\\nData is ready for loading if all checks passed.\")\n",
    "\n",
    "# Run validation\n",
    "validate_transformed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Schema Verification and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Define schema requirements\n",
    "schema = {\n",
    "    'census_records': {\n",
    "        'required_columns': ['record_id', 'census_year', 'source_pk'],\n",
    "        'integer_columns': ['record_id', 'census_year', 'source_pk'],\n",
    "        'varchar_columns': ['ed', 'page_number']\n",
    "    },\n",
    "    'locations': {\n",
    "        'required_columns': ['location_id', 'record_id'],\n",
    "        'integer_columns': ['location_id', 'record_id'],\n",
    "        'varchar_columns': ['street_name', 'house_num', 'build_num', 'dwelling_number', 'family_number']\n",
    "    },\n",
    "    'persons': {\n",
    "        'required_columns': ['person_id', 'first_name', 'last_name'],\n",
    "        'varchar_columns': ['person_id', 'first_name', 'last_name']\n",
    "    },\n",
    "    'personal_attributes': {\n",
    "        'required_columns': ['attribute_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['attribute_id', 'record_id', 'age'],\n",
    "        'varchar_columns': ['person_id', 'sex', 'race', 'place_birth']\n",
    "    },\n",
    "    'occupations': {\n",
    "        'required_columns': ['occupation_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['occupation_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'work', 'business']\n",
    "    },\n",
    "    'families': {\n",
    "        'required_columns': ['family_id', 'record_id', 'location_id'],\n",
    "        'integer_columns': ['record_id', 'location_id'],\n",
    "        'varchar_columns': ['family_id', 'head_first_name', 'head_last_name']\n",
    "    },\n",
    "    'relationships': {\n",
    "        'required_columns': ['relationship_id', 'person_id', 'family_id', 'record_id'],\n",
    "        'integer_columns': ['relationship_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'family_id', 'relation_to_head']\n",
    "    },\n",
    "    'property_status': {\n",
    "        'required_columns': ['property_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['property_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'owned_rented']\n",
    "    },\n",
    "    'marital_status': {\n",
    "        'required_columns': ['marital_id', 'person_id', 'record_id'],\n",
    "        'integer_columns': ['marital_id', 'record_id'],\n",
    "        'varchar_columns': ['person_id', 'marital_status']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading census data...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Read Census Data\n",
    "print(\"Reading census data...\")\n",
    "# Read the extracted CSV files\n",
    "census_dfs = {\n",
    "    1900: pd.read_csv('data/extracted/lakeland_1900_census.csv'),\n",
    "    1920: pd.read_csv('data/extracted/lakeland_1920_census.csv'),\n",
    "    1930: pd.read_csv('data/extracted/lakeland_1930_census.csv'),\n",
    "    1940: pd.read_csv('data/extracted/lakeland_1940_census.csv'),\n",
    "    1950: pd.read_csv('data/extracted/lakeland_1950_census.csv')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing 1900 census...\n",
      "Standardizing 1920 census...\n",
      "Standardizing 1930 census...\n",
      "Standardizing 1940 census...\n",
      "Standardizing 1950 census...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Standardize Columns\n",
    "def standardize_columns(df, year):\n",
    "    \"\"\"Standardize column names to match database schema\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert column names to lowercase and strip whitespace\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Standard column mappings\n",
    "    column_mapping = {\n",
    "        'pk': 'source_pk',\n",
    "        'dwelling number': 'dwelling_number',\n",
    "        'dwelling': 'dwelling_number',\n",
    "        'dwelling no': 'dwelling_number',\n",
    "        'dwelling_no': 'dwelling_number',\n",
    "        'house_number': 'house_num',\n",
    "        'house number': 'house_num',\n",
    "        'relation_head': 'relation_to_head',\n",
    "        'relation to head': 'relation_to_head',\n",
    "        'head_last': 'head_last_name',\n",
    "        'head last': 'head_last_name',\n",
    "        'head_first': 'head_first_name',\n",
    "        'head first': 'head_first_name',\n",
    "        'marital': 'marital_status',\n",
    "        'birth_place': 'place_birth',\n",
    "        'birth place': 'place_birth',\n",
    "        'family': 'family_number',\n",
    "        'family no': 'family_number',\n",
    "        'family_no': 'family_number',\n",
    "        'family number': 'family_number'\n",
    "    }\n",
    "    \n",
    "    # Apply mappings\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    df['census_year'] = year\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create standardized dataframes\n",
    "standardized_dfs = {}\n",
    "for year, df in census_dfs.items():\n",
    "    print(f\"Standardizing {year} census...\")\n",
    "    standardized_dfs[year] = standardize_columns(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create census_records table\n",
    "census_records_data = []\n",
    "record_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    census_records = pd.DataFrame({\n",
    "        'record_id': range(record_id_counter, record_id_counter + len(df)),\n",
    "        'census_year': df['census_year'].astype('Int64'),\n",
    "        'source_pk': df['source_pk'].astype('Int64'),\n",
    "        'ed': df['ed'] if 'ed' in df.columns else None,\n",
    "        'page_number': df['page_number'] if 'page_number' in df.columns else None\n",
    "    })\n",
    "    record_id_counter += len(df)\n",
    "    census_records_data.append(census_records)\n",
    "\n",
    "census_records_table = pd.concat(census_records_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create persons table with unique IDs\n",
    "def generate_person_id(year, index):\n",
    "    return f\"P{year}_{index:06d}\"\n",
    "\n",
    "persons_data = []\n",
    "for year, df in standardized_dfs.items():\n",
    "    persons = pd.DataFrame({\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'first_name': df['first_name'],\n",
    "        'last_name': df['last_name']\n",
    "    })\n",
    "    persons_data.append(persons)\n",
    "\n",
    "persons_table = pd.concat(persons_data, ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Created sequential dwelling_number for 1940 census\n",
      "Warning: Created sequential family_number for 1940 census\n",
      "Warning: Created sequential dwelling_number for 1950 census\n",
      "Warning: Created sequential family_number for 1950 census\n",
      "\n",
      "Locations Table Sample:\n",
      "   location_id  record_id street_name  house_num build_num  dwelling_number  \\\n",
      "0            1        612        None        NaN      None             32.0   \n",
      "1            2        613        None        NaN      None             32.0   \n",
      "2            3        614        None        NaN      None             32.0   \n",
      "3            4        615        None        NaN      None             32.0   \n",
      "4            5        616        None        NaN      None             32.0   \n",
      "\n",
      "   family_number  \n",
      "0           32.0  \n",
      "1           32.0  \n",
      "2           32.0  \n",
      "3           32.0  \n",
      "4           32.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bb/h215m9_n4s942nm7pw18_zrr0000gn/T/ipykernel_4281/1557219654.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  locations_table = pd.concat(locations_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create locations table\n",
    "locations_data = []\n",
    "location_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    # Create a base DataFrame with the required columns\n",
    "    locations = pd.DataFrame({\n",
    "        'location_id': range(location_id_counter, location_id_counter + len(df)),\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter)\n",
    "    })\n",
    "    \n",
    "    # Add optional columns if they exist, otherwise use None\n",
    "    optional_columns = {\n",
    "        'street_name': None,\n",
    "        'house_num': None,\n",
    "        'build_num': None,\n",
    "        'dwelling_number': None,\n",
    "        'family_number': None\n",
    "    }\n",
    "    \n",
    "    for col, default in optional_columns.items():\n",
    "        locations[col] = df[col] if col in df.columns else default\n",
    "        \n",
    "    # If dwelling_number is missing, create it from index\n",
    "    if locations['dwelling_number'].isna().all():\n",
    "        locations['dwelling_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential dwelling_number for {year} census\")\n",
    "    \n",
    "    # If family_number is missing, create it from index\n",
    "    if locations['family_number'].isna().all():\n",
    "        locations['family_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential family_number for {year} census\")\n",
    "    \n",
    "    location_id_counter += len(df)\n",
    "    locations_data.append(locations)\n",
    "\n",
    "locations_table = pd.concat(locations_data, ignore_index=True)\n",
    "\n",
    "# Print sample of the locations table\n",
    "print(\"\\nLocations Table Sample:\")\n",
    "print(locations_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 1900...\n",
      "Created 50 family records for year 1900\n",
      "\n",
      "Processing year 1920...\n",
      "Created 33 family records for year 1920\n",
      "\n",
      "Processing year 1930...\n",
      "Created 10 family records for year 1930\n",
      "\n",
      "Processing year 1940...\n",
      "Warning: Created sequential dwelling_number for 1940\n",
      "Warning: Created sequential family_number for 1940\n",
      "Created 61 family records for year 1940\n",
      "\n",
      "Processing year 1950...\n",
      "Warning: Created sequential dwelling_number for 1950\n",
      "Warning: Created sequential family_number for 1950\n",
      "Created 314 family records for year 1950\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0  F1900_000000        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "\n",
      "Family ID Statistics:\n",
      "Total number of families: 468\n",
      "Number of unique family IDs: 468\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create families table\n",
    "def generate_family_id(year, index):\n",
    "    return f\"F{year}_{index:06d}\"\n",
    "\n",
    "def ensure_family_columns(df, year):\n",
    "    \"\"\"Ensure required family columns exist and are properly formatted\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create dwelling_number if missing\n",
    "    if 'dwelling_number' not in df.columns:\n",
    "        df['dwelling_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential dwelling_number for {year}\")\n",
    "    \n",
    "    # Create family_number if missing\n",
    "    if 'family_number' not in df.columns:\n",
    "        df['family_number'] = range(1, len(df) + 1)\n",
    "        print(f\"Warning: Created sequential family_number for {year}\")\n",
    "    \n",
    "    # Convert to string and handle NaN values\n",
    "    df['dwelling_number'] = df['dwelling_number'].fillna(0).astype(int).astype(str)\n",
    "    df['family_number'] = df['family_number'].fillna(0).astype(int).astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "families_data = []\n",
    "family_id_maps = {}  # Store family ID mappings for each year\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    try:\n",
    "        print(f\"\\nProcessing year {year}...\")\n",
    "        \n",
    "        # Ensure required columns exist and are properly formatted\n",
    "        df = ensure_family_columns(df, year)\n",
    "        \n",
    "        # Group by dwelling and family number\n",
    "        family_groups = df.groupby(['dwelling_number', 'family_number'])\n",
    "        \n",
    "        # Get the first record for each family group\n",
    "        first_records = family_groups.first().reset_index()\n",
    "        num_families = len(first_records)\n",
    "        \n",
    "        # Create family IDs and store mapping\n",
    "        family_ids = [generate_family_id(year, i) for i in range(num_families)]\n",
    "        family_id_maps[year] = dict(zip(\n",
    "            zip(first_records['dwelling_number'], first_records['family_number']),\n",
    "            family_ids\n",
    "        ))\n",
    "        \n",
    "        # Create the families DataFrame\n",
    "        families = pd.DataFrame({\n",
    "            'family_id': family_ids,\n",
    "            'record_id': range(record_id_counter - num_families, record_id_counter),\n",
    "            'location_id': range(location_id_counter - num_families, location_id_counter),\n",
    "            'head_first_name': first_records['head_first_name'] if 'head_first_name' in first_records.columns else None,\n",
    "            'head_last_name': first_records['head_last_name'] if 'head_last_name' in first_records.columns else None\n",
    "        })\n",
    "        \n",
    "        families_data.append(families)\n",
    "        print(f\"Created {num_families} family records for year {year}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing year {year}\")\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "families_table = pd.concat(families_data, ignore_index=True)\n",
    "\n",
    "# Print sample and statistics\n",
    "print(\"\\nFamilies Table Sample:\")\n",
    "print(families_table.head())\n",
    "print(\"\\nFamily ID Statistics:\")\n",
    "print(f\"Total number of families: {len(families_table)}\")\n",
    "print(f\"Number of unique family IDs: {len(families_table['family_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create personal_attributes table\n",
    "def clean_age(age):\n",
    "    \"\"\"Convert age to integer, handling fractions\"\"\"\n",
    "    if pd.isna(age):\n",
    "        return None\n",
    "    try:\n",
    "        return int(float(age))\n",
    "    except (ValueError, TypeError):\n",
    "        if isinstance(age, str) and '/' in age:\n",
    "            num, denom = map(int, age.split('/'))\n",
    "            return max(0, int(num / denom))\n",
    "        return None\n",
    "\n",
    "personal_attributes_data = []\n",
    "attribute_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    attributes = pd.DataFrame({\n",
    "        'attribute_id': range(attribute_id_counter, attribute_id_counter + len(df)),\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "        'sex': df['sex'],\n",
    "        'race': df['race'],\n",
    "        'age': df['age'].apply(clean_age),\n",
    "        'place_birth': df['place_birth'] if 'place_birth' in df.columns else None\n",
    "    })\n",
    "    attribute_id_counter += len(df)\n",
    "    personal_attributes_data.append(attributes)\n",
    "\n",
    "personal_attributes_table = pd.concat(personal_attributes_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create occupations table\n",
    "occupations_data = []\n",
    "occupation_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    occupations = pd.DataFrame({\n",
    "        'occupation_id': range(occupation_id_counter, occupation_id_counter + len(df)),\n",
    "        'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "        'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "        'work': df['work'].replace({np.nan: None}),\n",
    "        'business': df['business'].replace({np.nan: None}) if 'business' in df.columns else None\n",
    "    })\n",
    "    occupation_id_counter += len(df)\n",
    "    occupations_data.append(occupations)\n",
    "\n",
    "occupations_table = pd.concat(occupations_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 186 relationship records for year 1900\n",
      "Created 186 relationship records for year 1920\n",
      "Created 50 relationship records for year 1930\n",
      "Created 61 relationship records for year 1940\n",
      "Created 314 relationship records for year 1950\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0  F1900_000000        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "\n",
      "Relationships Table Sample:\n",
      "   relationship_id     person_id     family_id  record_id relation_to_head\n",
      "0                1  P1900_000000  F1900_000000        612             Head\n",
      "1                2  P1900_000001  F1900_000000        613             Wife\n",
      "2                3  P1900_000002  F1900_000000        614              Son\n",
      "3                4  P1900_000003  F1900_000000        615              Son\n",
      "4                5  P1900_000004  F1900_000000        616              Son\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Create relationships table using the same family IDs\n",
    "relationships_data = []\n",
    "relationship_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    try:\n",
    "        # Ensure required columns exist\n",
    "        if 'dwelling_number' not in df.columns:\n",
    "            df['dwelling_number'] = range(1, len(df) + 1)\n",
    "        if 'family_number' not in df.columns:\n",
    "            df['family_number'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Get the family ID mapping for this year\n",
    "        year_family_map = family_id_maps[year]\n",
    "        \n",
    "        # Create family IDs using the same mapping as families table\n",
    "        family_ids = [year_family_map.get((d, f), generate_family_id(year, 0)) \n",
    "                     for d, f in zip(df['dwelling_number'], df['family_number'])]\n",
    "        \n",
    "        # Create relationships DataFrame\n",
    "        relationships = pd.DataFrame({\n",
    "            'relationship_id': range(relationship_id_counter, relationship_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'family_id': family_ids,\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'relation_to_head': df['relation_to_head'].fillna('Unknown')\n",
    "        })\n",
    "        \n",
    "        relationship_id_counter += len(df)\n",
    "        relationships_data.append(relationships)\n",
    "        print(f\"Created {len(relationships)} relationship records for year {year}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {str(e)}\")\n",
    "        print(\"DataFrame columns:\", df.columns.tolist())\n",
    "        raise\n",
    "\n",
    "relationships_table = pd.concat(relationships_data, ignore_index=True)\n",
    "\n",
    "# Print samples to verify\n",
    "print(\"\\nFamilies Table Sample:\")\n",
    "print(families_table.head())\n",
    "print(\"\\nRelationships Table Sample:\")\n",
    "print(relationships_table.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create property_status table\n",
    "property_status_data = []\n",
    "property_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    if 'owned_rented' in df.columns:\n",
    "        property_status = pd.DataFrame({\n",
    "            'property_id': range(property_id_counter, property_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'owned_rented': df['owned_rented'].replace({np.nan: None})\n",
    "        })\n",
    "        property_id_counter += len(df)\n",
    "        property_status_data.append(property_status)\n",
    "\n",
    "property_status_table = pd.concat(property_status_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Create marital_status table\n",
    "marital_status_data = []\n",
    "marital_id_counter = 1\n",
    "\n",
    "for year, df in standardized_dfs.items():\n",
    "    if 'marital_status' in df.columns:\n",
    "        marital = pd.DataFrame({\n",
    "            'marital_id': range(marital_id_counter, marital_id_counter + len(df)),\n",
    "            'person_id': [generate_person_id(year, i) for i in range(len(df))],\n",
    "            'record_id': range(record_id_counter - len(df), record_id_counter),\n",
    "            'marital_status': df['marital_status'].replace({np.nan: None})\n",
    "        })\n",
    "        marital_id_counter += len(df)\n",
    "        marital_status_data.append(marital)\n",
    "\n",
    "marital_status_table = pd.concat(marital_status_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debugging family IDs:\n",
      "\n",
      "Families table sample:\n",
      "      family_id\n",
      "0  F1900_000000\n",
      "1  F1900_000001\n",
      "2  F1900_000002\n",
      "3  F1900_000003\n",
      "4  F1900_000004\n",
      "\n",
      "Relationships table sample:\n",
      "      family_id\n",
      "0  F1900_000000\n",
      "1  F1900_000000\n",
      "2  F1900_000000\n",
      "3  F1900_000000\n",
      "4  F1900_000000\n",
      "\n",
      "Family ID counts:\n",
      "Number of unique family IDs in families table: 468\n",
      "Number of unique family IDs in relationships table: 5\n",
      "\n",
      "Debugging family IDs:\n",
      "Number of unique family IDs in families table: 468\n",
      "Number of unique family IDs in relationships table: 5\n",
      "All foreign key relationships verified!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Verify foreign key relationships\n",
    "def verify_foreign_keys():\n",
    "    \"\"\"Verify all foreign key relationships match the database schema\"\"\"\n",
    "    # Get all unique IDs from primary tables\n",
    "    record_ids = set(census_records_table['record_id'])\n",
    "    person_ids = set(persons_table['person_id'])\n",
    "    location_ids = set(locations_table['location_id'])\n",
    "    family_ids = set(families_table['family_id'])\n",
    "    \n",
    "    # Debug family IDs\n",
    "    print(\"\\nDebugging family IDs:\")\n",
    "    print(f\"Number of unique family IDs in families table: {len(family_ids)}\")\n",
    "    print(f\"Number of unique family IDs in relationships table: {len(set(relationships_table['family_id']))}\")\n",
    "    \n",
    "    # Find mismatched family IDs\n",
    "    relationship_family_ids = set(relationships_table['family_id'])\n",
    "    mismatched_ids = relationship_family_ids - family_ids\n",
    "    if mismatched_ids:\n",
    "        print(\"\\nExample of mismatched family IDs:\")\n",
    "        print(\"First 5 mismatched IDs:\", list(mismatched_ids)[:5])\n",
    "        print(\"\\nExample records from families table:\")\n",
    "        print(families_table[['family_id']].head())\n",
    "        print(\"\\nExample records from relationships table:\")\n",
    "        print(relationships_table[['family_id']].head())\n",
    "        raise AssertionError(f\"Found {len(mismatched_ids)} family IDs in relationships table that don't exist in families table\")\n",
    "\n",
    "    # Verify locations foreign keys\n",
    "    assert all(rid in record_ids for rid in locations_table['record_id']), \\\n",
    "        \"Invalid record_id in locations table\"\n",
    "\n",
    "    # Verify families foreign keys\n",
    "    assert all(rid in record_ids for rid in families_table['record_id']), \\\n",
    "        \"Invalid record_id in families table\"\n",
    "    assert all(lid in location_ids for lid in families_table['location_id']), \\\n",
    "        \"Invalid location_id in families table\"\n",
    "\n",
    "    # Verify personal_attributes foreign keys\n",
    "    assert all(pid in person_ids for pid in personal_attributes_table['person_id']), \\\n",
    "        \"Invalid person_id in personal_attributes table\"\n",
    "    assert all(rid in record_ids for rid in personal_attributes_table['record_id']), \\\n",
    "        \"Invalid record_id in personal_attributes table\"\n",
    "\n",
    "    # Verify occupations foreign keys\n",
    "    assert all(pid in person_ids for pid in occupations_table['person_id']), \\\n",
    "        \"Invalid person_id in occupations table\"\n",
    "    assert all(rid in record_ids for rid in occupations_table['record_id']), \\\n",
    "        \"Invalid record_id in occupations table\"\n",
    "\n",
    "    # Verify relationships foreign keys\n",
    "    assert all(pid in person_ids for pid in relationships_table['person_id']), \\\n",
    "        \"Invalid person_id in relationships table\"\n",
    "    assert all(fid in family_ids for fid in relationships_table['family_id']), \\\n",
    "        \"Invalid family_id in relationships table\"\n",
    "    assert all(rid in record_ids for rid in relationships_table['record_id']), \\\n",
    "        \"Invalid record_id in relationships table\"\n",
    "\n",
    "    print(\"All foreign key relationships verified!\")\n",
    "\n",
    "# Debug family IDs\n",
    "print(\"\\nDebugging family IDs:\")\n",
    "print(\"\\nFamilies table sample:\")\n",
    "print(families_table[['family_id']].head())\n",
    "print(\"\\nRelationships table sample:\")\n",
    "print(relationships_table[['family_id']].head())\n",
    "\n",
    "print(\"\\nFamily ID counts:\")\n",
    "print(f\"Number of unique family IDs in families table: {len(set(families_table['family_id']))}\")\n",
    "print(f\"Number of unique family IDs in relationships table: {len(set(relationships_table['family_id']))}\")\n",
    "\n",
    "# Find some mismatched IDs\n",
    "family_ids = set(families_table['family_id'])\n",
    "relationship_family_ids = set(relationships_table['family_id'])\n",
    "mismatched_ids = relationship_family_ids - family_ids\n",
    "if mismatched_ids:\n",
    "    print(\"\\nFirst 5 family IDs that exist in relationships but not in families:\")\n",
    "    print(list(mismatched_ids)[:5])\n",
    "    \n",
    "# Verify foreign keys\n",
    "verify_foreign_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data types to match PostgreSQL schema...\n",
      "\n",
      "Verifying data types after conversion:\n",
      "\n",
      "Locations table string columns:\n",
      "\n",
      "house_num:\n",
      "Sample values: [None, None, None, None, None]\n",
      "Data type: object\n",
      "\n",
      "dwelling_number:\n",
      "Sample values: ['32', '32', '32', '32', '32']\n",
      "Data type: object\n",
      "\n",
      "family_number:\n",
      "Sample values: ['32', '32', '32', '32', '32']\n",
      "Data type: object\n",
      "\n",
      "Personal attributes age column:\n",
      "Sample values: [58.0, 56.0, 22.0, 20.0, 15.0]\n",
      "Data type: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Data Type Conversion\n",
    "def convert_to_string(value):\n",
    "    \"\"\"Convert value to string, handling NaN and None\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Remove .0 from float strings\n",
    "    str_val = str(value).rstrip('.0')\n",
    "    return str_val if str_val != 'nan' else None\n",
    "\n",
    "def convert_to_integer(value):\n",
    "    \"\"\"Convert value to integer, handling NaN and None\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # First convert to float to handle any decimal values\n",
    "        float_val = float(value)\n",
    "        # Then convert to int, rounding down\n",
    "        return int(float_val)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def convert_to_postgres_types():\n",
    "    \"\"\"Convert DataFrame columns to match PostgreSQL schema types\"\"\"\n",
    "    global locations_table, census_records_table, personal_attributes_table\n",
    "    global persons_table, occupations_table, families_table\n",
    "    global relationships_table, property_status_table, marital_status_table\n",
    "    \n",
    "    # Convert locations table string columns\n",
    "    string_cols = ['street_name', 'house_num', 'build_num', 'dwelling_number', 'family_number']\n",
    "    for col in string_cols:\n",
    "        if col in locations_table.columns:\n",
    "            locations_table[col] = locations_table[col].apply(convert_to_string)\n",
    "    \n",
    "    # Convert census_records integer columns\n",
    "    census_records_table['census_year'] = census_records_table['census_year'].apply(convert_to_integer)\n",
    "    census_records_table['source_pk'] = census_records_table['source_pk'].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert census_records string columns\n",
    "    for col in ['ed', 'page_number']:\n",
    "        if col in census_records_table.columns:\n",
    "            census_records_table[col] = census_records_table[col].apply(convert_to_string)\n",
    "    \n",
    "    # Convert personal_attributes age to integer\n",
    "    if 'age' in personal_attributes_table.columns:\n",
    "        personal_attributes_table['age'] = personal_attributes_table['age'].apply(convert_to_integer)\n",
    "    \n",
    "    # Ensure all record_id fields are integers\n",
    "    for table in [locations_table, personal_attributes_table, occupations_table, \n",
    "                 families_table, relationships_table, property_status_table, \n",
    "                 marital_status_table]:\n",
    "        if 'record_id' in table.columns:\n",
    "            table['record_id'] = table['record_id'].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert IDENTITY columns to integers\n",
    "    id_columns = {\n",
    "        'locations_table': ['location_id'],\n",
    "        'personal_attributes_table': ['attribute_id'],\n",
    "        'occupations_table': ['occupation_id'],\n",
    "        'relationships_table': ['relationship_id'],\n",
    "        'property_status_table': ['property_id'],\n",
    "        'marital_status_table': ['marital_id']\n",
    "    }\n",
    "    \n",
    "    for table_name, columns in id_columns.items():\n",
    "        df = eval(table_name)\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(convert_to_integer)\n",
    "    \n",
    "    # Convert all varchar columns\n",
    "    varchar_columns = {\n",
    "        'persons_table': ['person_id', 'first_name', 'last_name'],\n",
    "        'personal_attributes_table': ['person_id', 'sex', 'race', 'place_birth'],\n",
    "        'occupations_table': ['person_id', 'work', 'business'],\n",
    "        'families_table': ['family_id', 'head_first_name', 'head_last_name'],\n",
    "        'relationships_table': ['person_id', 'family_id', 'relation_to_head'],\n",
    "        'property_status_table': ['person_id', 'owned_rented'],\n",
    "        'marital_status_table': ['person_id', 'marital_status']\n",
    "    }\n",
    "    \n",
    "    for table_name, columns in varchar_columns.items():\n",
    "        df = eval(table_name)\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(convert_to_string)\n",
    "\n",
    "# Run conversion\n",
    "print(\"Converting data types to match PostgreSQL schema...\")\n",
    "convert_to_postgres_types()\n",
    "\n",
    "# Verify conversions\n",
    "print(\"\\nVerifying data types after conversion:\")\n",
    "\n",
    "# Check locations table string columns\n",
    "print(\"\\nLocations table string columns:\")\n",
    "for col in ['house_num', 'dwelling_number', 'family_number']:\n",
    "    if col in locations_table.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"Sample values:\", locations_table[col].head().tolist())\n",
    "        print(\"Data type:\", locations_table[col].dtype)\n",
    "\n",
    "# Check personal_attributes age column\n",
    "print(\"\\nPersonal attributes age column:\")\n",
    "if 'age' in personal_attributes_table.columns:\n",
    "    print(\"Sample values:\", personal_attributes_table['age'].head().tolist())\n",
    "    print(\"Data type:\", personal_attributes_table['age'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting tables to CSV...\n",
      "Exported census_records to data/processed/census_records.csv\n",
      "\n",
      "Census_Records Table Sample:\n",
      "   record_id  census_year  source_pk    ed page_number\n",
      "0          1         1900          1  None        None\n",
      "1          2         1900          2  None        None\n",
      "2          3         1900          3  None        None\n",
      "3          4         1900          4  None        None\n",
      "4          5         1900          5  None        None\n",
      "Exported locations to data/processed/locations.csv\n",
      "\n",
      "Locations Table Sample:\n",
      "   location_id  record_id street_name house_num build_num dwelling_number  \\\n",
      "0            1        612        None      None      None              32   \n",
      "1            2        613        None      None      None              32   \n",
      "2            3        614        None      None      None              32   \n",
      "3            4        615        None      None      None              32   \n",
      "4            5        616        None      None      None              32   \n",
      "\n",
      "  family_number  \n",
      "0            32  \n",
      "1            32  \n",
      "2            32  \n",
      "3            32  \n",
      "4            32  \n",
      "Exported persons to data/processed/persons.csv\n",
      "\n",
      "Persons Table Sample:\n",
      "      person_id first_name      last_name\n",
      "0        P1900_       Ezra  Vanvalkenburg\n",
      "1  P1900_000001     Hattie  Vanvalkenburg\n",
      "2  P1900_000002    William  Vanvalkenburg\n",
      "3  P1900_000003        Jay  Vanvalkenburg\n",
      "4  P1900_000004     Jessie  Vanvalkenburg\n",
      "Exported personal_attributes to data/processed/personal_attributes.csv\n",
      "\n",
      "Personal_Attributes Table Sample:\n",
      "   attribute_id     person_id  record_id sex race   age place_birth\n",
      "0             1        P1900_        612   M    W  58.0    New York\n",
      "1             2  P1900_000001        613   F    W  56.0    New York\n",
      "2             3  P1900_000002        614   M    W  22.0    New York\n",
      "3             4  P1900_000003        615   M    W  20.0    New York\n",
      "4             5  P1900_000004        616   F    W  15.0    New York\n",
      "Exported occupations to data/processed/occupations.csv\n",
      "\n",
      "Occupations Table Sample:\n",
      "   occupation_id     person_id  record_id         work business\n",
      "0              1        P1900_        612     Merchant     None\n",
      "1              2  P1900_000001        613         None     None\n",
      "2              3  P1900_000002        614  Bakes Bread     None\n",
      "3              4  P1900_000003        615        Baker     None\n",
      "4              5  P1900_000004        616    At School     None\n",
      "Exported families to data/processed/families.csv\n",
      "\n",
      "Families Table Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0        F1900_        748          748         Ewell A           Dick\n",
      "1  F1900_000001        749          749         William          Davis\n",
      "2  F1900_000002        750          750         James F         Meegan\n",
      "3  F1900_000003        751          751          Andrew           Hill\n",
      "4  F1900_000004        752          752          Joseph         Tucker\n",
      "Exported relationships to data/processed/relationships.csv\n",
      "\n",
      "Relationships Table Sample:\n",
      "   relationship_id     person_id family_id  record_id relation_to_head\n",
      "0                1        P1900_    F1900_        612             Head\n",
      "1                2  P1900_000001    F1900_        613             Wife\n",
      "2                3  P1900_000002    F1900_        614              Son\n",
      "3                4  P1900_000003    F1900_        615              Son\n",
      "4                5  P1900_000004    F1900_        616              Son\n",
      "Exported property_status to data/processed/property_status.csv\n",
      "\n",
      "Property_Status Table Sample:\n",
      "   property_id     person_id  record_id owned_rented\n",
      "0            1        P1900_        612            O\n",
      "1            2  P1900_000001        613         None\n",
      "2            3  P1900_000002        614         None\n",
      "3            4  P1900_000003        615         None\n",
      "4            5  P1900_000004        616         None\n",
      "Exported marital_status to data/processed/marital_status.csv\n",
      "\n",
      "Marital_Status Table Sample:\n",
      "   marital_id     person_id  record_id marital_status\n",
      "0           1        P1900_        612              M\n",
      "1           2  P1900_000001        613              M\n",
      "2           3  P1900_000002        614              S\n",
      "3           4  P1900_000003        615              S\n",
      "4           5  P1900_000004        616              S\n",
      "\n",
      "All tables exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Export Tables\n",
    "# Export tables to CSV\n",
    "print(\"Exporting tables to CSV...\")\n",
    "tables_to_export = {\n",
    "    'census_records': census_records_table,\n",
    "    'locations': locations_table,\n",
    "    'persons': persons_table,\n",
    "    'personal_attributes': personal_attributes_table,\n",
    "    'occupations': occupations_table,\n",
    "    'families': families_table,\n",
    "    'relationships': relationships_table,\n",
    "    'property_status': property_status_table,\n",
    "    'marital_status': marital_status_table\n",
    "}\n",
    "\n",
    "for table_name, df in tables_to_export.items():\n",
    "    output_path = f'data/processed/{table_name}.csv'\n",
    "    df.to_csv(output_path, index=False, na_rep='NULL')\n",
    "    print(f\"Exported {table_name} to {output_path}\")\n",
    "    print(f\"\\n{table_name.title()} Table Sample:\")\n",
    "    print(df.head())\n",
    "\n",
    "print(\"\\nAll tables exported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading tables...\n",
      "Fixing locations table string columns...\n",
      "Fixing personal_attributes age column...\n",
      "Saving updated tables...\n",
      "Data type conversion complete. Showing samples:\n",
      "\n",
      "Locations table sample:\n",
      "  house_num dwelling_number family_number\n",
      "0      None            32.0          32.0\n",
      "1      None            32.0          32.0\n",
      "2      None            32.0          32.0\n",
      "3      None            32.0          32.0\n",
      "4      None            32.0          32.0\n",
      "\n",
      "Personal attributes age column sample:\n",
      "    age\n",
      "0  58.0\n",
      "1  56.0\n",
      "2  22.0\n",
      "3  20.0\n",
      "4  15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Reading tables...\")\n",
    "# Read the tables\n",
    "locations_df = pd.read_csv('data/processed/locations.csv')\n",
    "personal_attributes_df = pd.read_csv('data/processed/personal_attributes.csv')\n",
    "\n",
    "print(\"Fixing locations table string columns...\")\n",
    "# Convert numeric columns to strings in locations table\n",
    "locations_df['house_num'] = locations_df['house_num'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "locations_df['dwelling_number'] = locations_df['dwelling_number'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "locations_df['family_number'] = locations_df['family_number'].fillna('').astype(str).replace({'nan': None, '': None})\n",
    "\n",
    "print(\"Fixing personal_attributes age column...\")\n",
    "# Fix age values in personal_attributes table\n",
    "def clean_age(age):\n",
    "    if pd.isna(age):\n",
    "        return None\n",
    "    try:\n",
    "        # Handle float values\n",
    "        if isinstance(age, (int, float)):\n",
    "            return int(age)\n",
    "        # Handle string values\n",
    "        age_str = str(age).strip()\n",
    "        if age_str.replace('.', '').isdigit():\n",
    "            return int(float(age_str))\n",
    "        return None\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "personal_attributes_df['age'] = personal_attributes_df['age'].apply(clean_age)\n",
    "\n",
    "print(\"Saving updated tables...\")\n",
    "# Save the updated tables\n",
    "locations_df.to_csv('data/processed/locations.csv', index=False)\n",
    "personal_attributes_df.to_csv('data/processed/personal_attributes.csv', index=False)\n",
    "\n",
    "print(\"Data type conversion complete. Showing samples:\")\n",
    "print(\"\\nLocations table sample:\")\n",
    "print(locations_df[['house_num', 'dwelling_number', 'family_number']].head())\n",
    "print(\"\\nPersonal attributes age column sample:\")\n",
    "print(personal_attributes_df[['age']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning locations data...\n",
      "Fixed locations string columns\n",
      "\n",
      "Cleaning personal attributes data...\n",
      "Fixed age column in personal attributes\n",
      "\n",
      "Cleaning persons data...\n",
      "Found 16 records with null last names\n",
      "Fixed null last names in persons table\n",
      "\n",
      "Fixing family IDs...\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal data cleaning complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Run final cleaning\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mfinal_data_cleaning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[17], line 63\u001b[0m, in \u001b[0;36mfinal_data_cleaning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m relationships_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relationships_df\u001b[38;5;241m.\u001b[39mapply(create_family_id, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Create mapping for families table\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m families_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcensus_year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfamilies_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelationships_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcensus_year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m families_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m families_df\u001b[38;5;241m.\u001b[39mapply(create_family_id, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Drop temporary census_year columns\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4703\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/algorithms.py:1732\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     mapper \u001b[38;5;241m=\u001b[39m mapper[mapper\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnotna()]\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# Since values were input this means we came from either\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# a dict or a series and mapper should be an index\u001b[39;00m\n\u001b[0;32m-> 1732\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m new_values \u001b[38;5;241m=\u001b[39m take_nd(mapper\u001b[38;5;241m.\u001b[39m_values, indexer)\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m/opt/anaconda3/envs/lakeland/lib/python3.11/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def final_data_cleaning():\n",
    "    \"\"\"Perform final data cleaning before export\"\"\"\n",
    "    \n",
    "    # Fix locations data\n",
    "    print(\"Cleaning locations data...\")\n",
    "    locations_df = pd.read_csv('data/processed/locations.csv')\n",
    "    string_columns = ['house_num', 'dwelling_number', 'family_number']\n",
    "    for col in string_columns:\n",
    "        # Convert to string but keep NaN as NaN\n",
    "        locations_df[col] = locations_df[col].astype(str).replace('nan', np.nan)\n",
    "        # Remove .0 from the end of numbers\n",
    "        locations_df[col] = locations_df[col].apply(lambda x: x.replace('.0', '') if pd.notnull(x) else x)\n",
    "    locations_df.to_csv('data/processed/locations.csv', index=False)\n",
    "    print(\"Fixed locations string columns\")\n",
    "    \n",
    "    # Fix personal attributes data\n",
    "    print(\"\\nCleaning personal attributes data...\")\n",
    "    attributes_df = pd.read_csv('data/processed/personal_attributes.csv')\n",
    "    attributes_df['age'] = pd.to_numeric(attributes_df['age'], errors='coerce').astype('Int64')\n",
    "    attributes_df.to_csv('data/processed/personal_attributes.csv', index=False)\n",
    "    print(\"Fixed age column in personal attributes\")\n",
    "    \n",
    "    # Fix null last names in persons table\n",
    "    print(\"\\nCleaning persons data...\")\n",
    "    persons_df = pd.read_csv('data/processed/persons.csv')\n",
    "    null_last_names = persons_df[persons_df['last_name'].isna()]\n",
    "    if len(null_last_names) > 0:\n",
    "        print(f\"Found {len(null_last_names)} records with null last names\")\n",
    "        persons_df['last_name'] = persons_df['last_name'].fillna('Unknown')\n",
    "        persons_df.to_csv('data/processed/persons.csv', index=False)\n",
    "        print(\"Fixed null last names in persons table\")\n",
    "    \n",
    "    # Fix family IDs in relationships and families tables\n",
    "    print(\"\\nFixing family IDs...\")\n",
    "    relationships_df = pd.read_csv('data/processed/relationships.csv')\n",
    "    families_df = pd.read_csv('data/processed/families.csv')\n",
    "    \n",
    "    # Create a mapping of record_ids to census years using person_ids\n",
    "    def get_census_year(person_id):\n",
    "        if pd.notnull(person_id) and person_id.startswith('P'):\n",
    "            return person_id[1:5]\n",
    "        return None\n",
    "    \n",
    "    # Add census year to relationships table\n",
    "    relationships_df['census_year'] = relationships_df['person_id'].apply(get_census_year)\n",
    "    \n",
    "    # Group by the base family_id and get the census year\n",
    "    family_years = relationships_df.groupby('family_id')['census_year'].first()\n",
    "    \n",
    "    # Create mapping of record_ids to complete family IDs\n",
    "    def create_family_id(row):\n",
    "        if pd.isnull(row['family_id']):\n",
    "            return None\n",
    "        year = row['census_year']\n",
    "        base_id = row['family_id'].split('_')[0] + '_'  # Get F1900_, F1920_, etc.\n",
    "        sequence = str(row['record_id']).zfill(6)  # Pad record_id to 6 digits\n",
    "        return f\"{base_id}{sequence}\"\n",
    "    \n",
    "    # Update family IDs in relationships table\n",
    "    relationships_df['family_id'] = relationships_df.apply(create_family_id, axis=1)\n",
    "    \n",
    "    # Create mapping for families table\n",
    "    families_df['census_year'] = families_df['record_id'].map(\n",
    "        relationships_df.set_index('record_id')['census_year']\n",
    "    )\n",
    "    families_df['family_id'] = families_df.apply(create_family_id, axis=1)\n",
    "    \n",
    "    # Drop temporary census_year columns\n",
    "    relationships_df = relationships_df.drop('census_year', axis=1)\n",
    "    families_df = families_df.drop('census_year', axis=1)\n",
    "    \n",
    "    # Save updated relationships and families data\n",
    "    relationships_df.to_csv('data/processed/relationships.csv', index=False)\n",
    "    print(\"Fixed family IDs in relationships table\")\n",
    "    \n",
    "    # Clean families data and fix location IDs\n",
    "    print(\"\\nCleaning families data...\")\n",
    "    \n",
    "    # Create mapping from record_id to location_id using locations table\n",
    "    location_map = dict(zip(locations_df['record_id'], locations_df['location_id']))\n",
    "    \n",
    "    # Update location_ids in families table\n",
    "    families_df['location_id'] = families_df['record_id'].map(location_map)\n",
    "    \n",
    "    # Ensure correct data types for families\n",
    "    families_df['record_id'] = families_df['record_id'].astype(int)\n",
    "    families_df['location_id'] = families_df['location_id'].astype(int)\n",
    "    families_df['family_id'] = families_df['family_id'].astype(str)\n",
    "    \n",
    "    # Fill any null values in head names\n",
    "    families_df['head_first_name'] = families_df['head_first_name'].fillna('Unknown')\n",
    "    families_df['head_last_name'] = families_df['head_last_name'].fillna('Unknown')\n",
    "    \n",
    "    families_df.to_csv('data/processed/families.csv', index=False)\n",
    "    print(\"Cleaned families data and fixed location IDs\")\n",
    "    \n",
    "    print(\"\\nFinal data cleaning complete!\")\n",
    "\n",
    "# Run final cleaning\n",
    "final_data_cleaning() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Transform Summary:\n",
      "--------------------------------------------------\n",
      "\n",
      "census_records:\n",
      "  Rows: 797\n",
      "  Columns: record_id, census_year, source_pk, ed, page_number\n",
      "  Sample:\n",
      "   record_id  census_year  source_pk    ed page_number\n",
      "0          1         1900          1  None        None\n",
      "1          2         1900          2  None        None\n",
      "--------------------------------------------------\n",
      "\n",
      "locations:\n",
      "  Rows: 797\n",
      "  Columns: location_id, record_id, street_name, house_num, build_num, dwelling_number, family_number\n",
      "  Sample:\n",
      "   location_id  record_id street_name  house_num build_num  dwelling_number  \\\n",
      "0            1        612        None        NaN      None             32.0   \n",
      "1            2        613        None        NaN      None             32.0   \n",
      "\n",
      "   family_number  \n",
      "0           32.0  \n",
      "1           32.0  \n",
      "--------------------------------------------------\n",
      "\n",
      "persons:\n",
      "  Rows: 797\n",
      "  Columns: person_id, first_name, last_name\n",
      "  Sample:\n",
      "      person_id first_name      last_name\n",
      "0  P1900_000000       Ezra  Vanvalkenburg\n",
      "1  P1900_000001     Hattie  Vanvalkenburg\n",
      "--------------------------------------------------\n",
      "\n",
      "personal_attributes:\n",
      "  Rows: 797\n",
      "  Columns: attribute_id, person_id, record_id, sex, race, age, place_birth\n",
      "  Sample:\n",
      "   attribute_id     person_id  record_id sex race   age place_birth\n",
      "0             1  P1900_000000        612   M    W  58.0    New York\n",
      "1             2  P1900_000001        613   F    W  56.0    New York\n",
      "--------------------------------------------------\n",
      "\n",
      "occupations:\n",
      "  Rows: 797\n",
      "  Columns: occupation_id, person_id, record_id, work, business\n",
      "  Sample:\n",
      "   occupation_id     person_id  record_id      work business\n",
      "0              1  P1900_000000        612  Merchant     None\n",
      "1              2  P1900_000001        613      None     None\n",
      "--------------------------------------------------\n",
      "\n",
      "families:\n",
      "  Rows: 468\n",
      "  Columns: family_id, record_id, location_id, head_first_name, head_last_name\n",
      "  Sample:\n",
      "      family_id  record_id  location_id head_first_name head_last_name\n",
      "0  F1900_000000        748          748            Ezra  Vanvalkenburg\n",
      "1  F1900_000001        749          749      John Henry       Flanagan\n",
      "--------------------------------------------------\n",
      "\n",
      "relationships:\n",
      "  Rows: 797\n",
      "  Columns: relationship_id, person_id, family_id, record_id, relation_to_head\n",
      "  Sample:\n",
      "   relationship_id     person_id     family_id  record_id relation_to_head\n",
      "0                1  P1900_000000  F1900_000000        612             Head\n",
      "1                2  P1900_000001  F1900_000000        613             Wife\n",
      "--------------------------------------------------\n",
      "\n",
      "property_status:\n",
      "  Rows: 483\n",
      "  Columns: property_id, person_id, record_id, owned_rented\n",
      "  Sample:\n",
      "   property_id     person_id  record_id owned_rented\n",
      "0            1  P1900_000000        612            O\n",
      "1            2  P1900_000001        613         None\n",
      "--------------------------------------------------\n",
      "\n",
      "marital_status:\n",
      "  Rows: 797\n",
      "  Columns: marital_id, person_id, record_id, marital_status\n",
      "  Sample:\n",
      "   marital_id     person_id  record_id marital_status\n",
      "0           1  P1900_000000        612              M\n",
      "1           2  P1900_000001        613              M\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Print summary statistics\n",
    "print(\"\\nData Transform Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for table_name, df in tables.items():\n",
    "    print(f\"\\n{table_name}:\")\n",
    "    print(f\"  Rows: {len(df)}\")\n",
    "    print(f\"  Columns: {', '.join(df.columns)}\")\n",
    "    print(f\"  Sample:\")\n",
    "    print(df.head(2))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
